"""
iFlow CLI Workflow Pipelineé€‚é…å™¨å•å…ƒæµ‹è¯•

éµå¾ªæµ‹è¯•é©±åŠ¨å¼€å‘(TDD)åŸåˆ™ï¼Œå…ˆåˆ›å»ºæµ‹è¯•ç”¨ä¾‹ï¼Œå†å®ç°å…·ä½“åŠŸèƒ½ã€‚
æµ‹è¯•iFlow CLIçš„Workflow Pipelineé›†æˆæœºåˆ¶ã€‚
"""

import pytest
import asyncio
import json
import datetime
from unittest.mock import Mock, AsyncMock, patch, MagicMock
from typing import Dict, Any, Optional, List
from pathlib import Path

# å¯¼å…¥è¢«æµ‹è¯•çš„æ¨¡å—
from src.adapters.codex.natural_language_parser import IntentResult


class MockIFlowPipelineContext:
    """æ¨¡æ‹ŸiFlow CLI Pipelineä¸Šä¸‹æ–‡"""
    def __init__(self, workflow_id: str = "", stage: str = "", data: Dict = None):
        self.workflow_id = workflow_id or "test-workflow"
        self.stage = stage or "input"
        self.data = data or {}
        self.metadata = {
            'user_id': 'test_user',
            'session_id': 'test_session',
            'pipeline_config': {}
        }
        self.pipeline_name = "cross-cli-integration"
        self.version = "1.0.0"


class TestIFlowWorkflowAdapterTDD:
    """iFlow CLI Workflow Pipelineé€‚é…å™¨TDDæµ‹è¯• - éµå¾ªæµ‹è¯•å…ˆè¡Œçš„åŸåˆ™"""

    @pytest.fixture
    def mock_adapter_class(self):
        """Mocké€‚é…å™¨ç±»ç”¨äºTDD"""
        class IFlowWorkflowAdapter:
            def __init__(self, cli_name: str):
                self.cli_name = cli_name
                self.version = "1.0.0"
                self.pipeline_stages = []
                self.processed_workflows = []
                self.workflow_executions = []
                self.pipeline_hooks = {}
                self.stages_processed = 0
                self.cross_cli_calls_count = 0

            async def execute_task(self, task: str, context: Dict[str, Any]) -> str:
                """æ¨¡æ‹Ÿæ‰§è¡Œè·¨CLIä»»åŠ¡"""
                self.cross_cli_calls_count += 1
                self.workflow_executions.append({
                    'task': task,
                    'context': context,
                    'timestamp': datetime.datetime.now().isoformat()
                })
                return f"[iFlow â†’ {context.get('target_cli', 'unknown').upper()} è°ƒç”¨ç»“æœ]\næ¨¡æ‹Ÿæ‰§è¡Œ: {task}"

            def is_available(self) -> bool:
                """æ£€æŸ¥é€‚é…å™¨æ˜¯å¦å¯ç”¨"""
                return len(self.pipeline_stages) > 0

            async def health_check(self) -> Dict[str, Any]:
                """å¥åº·æ£€æŸ¥"""
                return {
                    'cli_name': self.cli_name,
                    'available': self.is_available(),
                    'version': self.version,
                    'pipeline_stages_count': len(self.pipeline_stages),
                    'processed_workflows_count': len(self.processed_workflows),
                    'cross_cli_calls_count': self.cross_cli_calls_count
                }

            def get_statistics(self) -> Dict[str, Any]:
                """è·å–ç»Ÿè®¡ä¿¡æ¯"""
                return {
                    'cli_name': self.cli_name,
                    'version': self.version,
                    'pipeline_stages_count': len(self.pipeline_stages),
                    'processed_workflows_count': len(self.processed_workflows),
                    'cross_cli_calls_count': self.cross_cli_calls_count,
                    'stages_processed': self.stages_processed
                }

    @pytest.fixture
    def adapter(self, mock_adapter_class):
        """åˆ›å»ºé€‚é…å™¨å®ä¾‹"""
        return mock_adapter_class("iflow")

    @pytest.fixture
    def mock_context(self):
        """åˆ›å»ºæ¨¡æ‹ŸPipelineä¸Šä¸‹æ–‡"""
        return MockIFlowPipelineContext(
            workflow_id="test-workflow-001",
            stage="input_validation",
            data={"prompt": "è¯·ç”¨claudeå¸®æˆ‘åˆ†æè¿™ä¸ªç®—æ³•"}
        )

    # ==================== TDDæµ‹è¯•ç”¨ä¾‹ ====================

    @pytest.mark.unit
    async def test_adapter_initialization(self, adapter):
        """æµ‹è¯•é€‚é…å™¨åˆå§‹åŒ–"""
        result = await adapter.initialize()

        assert result is True, "é€‚é…å™¨åˆå§‹åŒ–åº”è¯¥æˆåŠŸ"
        assert adapter.is_available() is True, "åˆå§‹åŒ–åé€‚é…å™¨åº”è¯¥å¯ç”¨"
        assert len(adapter.pipeline_stages) > 0, "åº”è¯¥åŠ è½½Pipelineé˜¶æ®µ"
        assert len(adapter.pipeline_hooks) > 0, "åº”è¯¥æ³¨å†ŒPipeline Hooks"

    @pytest.mark.unit
    async def test_pipeline_configuration_loading(self, adapter):
        """æµ‹è¯•Pipelineé…ç½®åŠ è½½"""
        await adapter.initialize()

        assert hasattr(adapter, 'pipeline_config'), "åº”è¯¥åŠ è½½Pipelineé…ç½®"

        # éªŒè¯é…ç½®ç»“æ„
        if hasattr(adapter, 'pipeline_config'):
            config = adapter.pipeline_config
            assert 'adapter_name' in config, "é…ç½®åº”åŒ…å«é€‚é…å™¨åç§°"
            assert 'pipeline_mechanism' in config, "é…ç½®åº”åŒ…å«Pipelineæœºåˆ¶"

    @pytest.mark.unit
    async def test_pipeline_stages_registration(self, adapter):
        """æµ‹è¯•Pipelineé˜¶æ®µæ³¨å†Œ"""
        await adapter.initialize()

        expected_stages = [
            'input_validation',
            'cross_cli_detection',
            'target_execution',
            'result_processing',
            'output_formatting'
        ]

        assert adapter.pipeline_stages == expected_stages, "åº”è¯¥æ³¨å†Œæ­£ç¡®çš„Pipelineé˜¶æ®µ"

    @pytest.mark.unit
    async def test_workflow_hooks_setup(self, adapter):
        """æµ‹è¯•Workflow Hooksè®¾ç½®"""
        await adapter.initialize()

        expected_hooks = [
            'on_workflow_start',
            'on_stage_complete',
            'on_workflow_success',
            'on_workflow_error',
            'on_pipeline_ready'
        ]

        assert set(adapter.pipeline_hooks.keys()) == set(expected_hooks), "åº”è¯¥è®¾ç½®æ­£ç¡®çš„Workflow Hooks"

    @pytest.mark.unit
    async def test_cross_cli_detection_in_workflow(self, adapter, mock_context):
        """æµ‹è¯•å·¥ä½œæµä¸­çš„è·¨CLIæ£€æµ‹"""
        await adapter.initialize()

        # æµ‹è¯•è·¨CLIè°ƒç”¨æ£€æµ‹
        mock_context.data = {"prompt": "è¯·ç”¨claudeå¸®æˆ‘åˆ†ææ•°æ®"}
        is_cross_cli = adapter._detect_cross_cli_intent(mock_context)

        assert is_cross_cli is True, "åº”è¯¥æ£€æµ‹åˆ°è·¨CLIè°ƒç”¨æ„å›¾"

    @pytest.mark.unit
    async def test_workflow_stage_processing_with_cross_cli(self, adapter, mock_context):
        """æµ‹è¯•åŒ…å«è·¨CLIçš„å·¥ä½œæµé˜¶æ®µå¤„ç†"""
        await adapter.initialize()

        mock_context.data = {"prompt": "ä½¿ç”¨geminiå¤„ç†è¿™ä¸ªæ–‡æœ¬"}
        result = await adapter.on_workflow_start(mock_context)

        assert result is not None, "è·¨CLIè°ƒç”¨åº”è¯¥è¿”å›ç»“æœ"
        assert "gemini" in result.lower(), "ç»“æœåº”è¯¥åŒ…å«ç›®æ ‡CLIåç§°"
        assert "å·¥ä½œæµç»“æœ" in result, "ç»“æœåº”è¯¥æ˜¯å·¥ä½œæµæ ¼å¼"

    @pytest.mark.unit
    async def test_workflow_stage_processing_normal_task(self, adapter, mock_context):
        """æµ‹è¯•æ™®é€šä»»åŠ¡çš„å·¥ä½œæµé˜¶æ®µå¤„ç†"""
        await adapter.initialize()

        mock_context.data = {"prompt": "æ­£å¸¸çš„æ•°æ®å¤„ç†ä»»åŠ¡"}
        result = await adapter.on_workflow_start(mock_context)

        assert result is None, "æ™®é€šä»»åŠ¡åº”è¯¥è¿”å›Noneï¼Œç»§ç»­æ­£å¸¸æµç¨‹"
        assert adapter.stages_processed > 0, "åº”è¯¥å¤„ç†äº†å·¥ä½œæµé˜¶æ®µ"

    @pytest.mark.unit
    async def test_workflow_self_reference_handling(self, adapter, mock_context):
        """æµ‹è¯•å·¥ä½œæµè‡ªæˆ‘å¼•ç”¨å¤„ç†"""
        await adapter.initialize()

        mock_context.data = {"prompt": "ä½¿ç”¨iflowå¤„ç†è¿™ä¸ªå·¥ä½œæµ"}
        target_cli, task = adapter._parse_cross_cli_task(mock_context)

        # åº”è¯¥ä¸è§¦å‘è·¨CLIè°ƒç”¨ï¼ˆé¿å…è‡ªæˆ‘å¼•ç”¨ï¼‰
        result = await adapter.on_workflow_start(mock_context)
        assert result is None, "è‡ªæˆ‘å¼•ç”¨åº”è¯¥è¿”å›None"

    @pytest.mark.unit
    async def test_multiple_target_cli_support(self, adapter, mock_context):
        """æµ‹è¯•å¤šç›®æ ‡CLIæ”¯æŒ"""
        await adapter.initialize()

        supported_clis = ['claude', 'gemini', 'qwencode', 'qoder', 'codebuddy', 'codex']

        for cli in supported_clis:
            mock_context.data = {"prompt": f"è¯·ç”¨{cli}å¸®æˆ‘å¤„ç†ä»»åŠ¡"}
            result = await adapter.on_workflow_start(mock_context)

            assert result is not None, f"åº”è¯¥æ”¯æŒ{cli}çš„è·¨CLIè°ƒç”¨"
            assert cli.upper() in result, f"ç»“æœåº”è¯¥åŒ…å«{cli}"

    @pytest.mark.unit
    async def test_pipeline_hooks_configuration(self, adapter):
        """æµ‹è¯•Pipeline Hooksé…ç½®"""
        await adapter.initialize()

        # éªŒè¯æ¯ä¸ªHookéƒ½æ˜¯å¯è°ƒç”¨çš„
        for hook_name, hook_func in adapter.pipeline_hooks.items():
            assert callable(hook_func), f"Hook {hook_name} åº”è¯¥æ˜¯å¯è°ƒç”¨çš„"

    @pytest.mark.unit
    async def test_workflow_result_formatting_consistency(self, adapter, mock_context):
        """æµ‹è¯•å·¥ä½œæµç»“æœæ ¼å¼åŒ–ä¸€è‡´æ€§"""
        await adapter.initialize()

        mock_context.data = {"prompt": "è¯·ç”¨claudeåˆ†æè¿™ä¸ªç®—æ³•"}
        result = await adapter.on_workflow_start(mock_context)

        # éªŒè¯æ ¼å¼åŒ–ç»“æ„
        required_elements = [
            "ğŸ”„ è·¨CLIå·¥ä½œæµç»“æœ",
            "æºå·¥ä½œæµ**: iFlow Pipeline",
            "ç›®æ ‡CLI**: CLAUDE",
            "å·¥ä½œæµé˜¶æ®µ",
            "æ‰§è¡Œæ—¶é—´",
            "Claudeå·¥ä½œæµç»“æœ",
            "é€šè¿‡Workflow Pipelineæä¾›"
        ]

        for element in required_elements:
            assert element in result, f"å·¥ä½œæµç»“æœæ ¼å¼åº”è¯¥åŒ…å«: {element}"

    @pytest.mark.unit
    async def test_workflow_error_handling(self, adapter, mock_context):
        """æµ‹è¯•å·¥ä½œæµé”™è¯¯å¤„ç†"""
        await adapter.initialize()

        # æ¨¡æ‹Ÿå·¥ä½œæµé”™è¯¯
        test_error = Exception("å·¥ä½œæµæ‰§è¡Œé”™è¯¯")
        result = await adapter.on_workflow_error(mock_context, test_error)

        assert result is None, "é”™è¯¯å¤„ç†åº”è¯¥è¿”å›None"

        # éªŒè¯é”™è¯¯è¢«è®°å½•
        error_records = [w for w in adapter.processed_workflows if w.get('type') == 'workflow_error']
        assert len(error_records) > 0, "åº”è¯¥è®°å½•å·¥ä½œæµé”™è¯¯"

    @pytest.mark.unit
    async def test_concurrent_workflow_processing(self, adapter, mock_context):
        """æµ‹è¯•å¹¶å‘å·¥ä½œæµå¤„ç†"""
        await adapter.initialize()

        # åˆ›å»ºå¤šä¸ªå¹¶å‘å·¥ä½œæµ
        workflows = []
        for i in range(3):
            workflow_context = MockIFlowPipelineContext(
                workflow_id=f"concurrent-workflow-{i}",
                stage="input_validation",
                data={"prompt": f"è¯·ç”¨geminiå¤„ç†ä»»åŠ¡{i}"}
            )
            workflows.append(adapter.on_workflow_start(workflow_context))

        # å¹¶å‘æ‰§è¡Œ
        results = await asyncio.gather(*workflows)

        # éªŒè¯ç»“æœ
        for i, result in enumerate(results):
            assert result is not None, f"å¹¶å‘å·¥ä½œæµ{i}åº”è¯¥è¿”å›ç»“æœ"
            assert "gemini" in result.lower(), f"ç»“æœ{i}åº”è¯¥åŒ…å«ç›®æ ‡CLI"

    @pytest.mark.unit
    async def test_workflow_statistics_tracking(self, adapter, mock_context):
        """æµ‹è¯•å·¥ä½œæµç»Ÿè®¡è·Ÿè¸ª"""
        await adapter.initialize()

        # æ‰§è¡Œå‡ ä¸ªå·¥ä½œæµ
        await adapter.on_workflow_start(mock_context)
        await adapter.on_stage_complete(mock_context, "stage_result")
        await adapter.on_workflow_success(mock_context, "final_result")

        # éªŒè¯ç»Ÿè®¡
        assert adapter.stages_processed > 0, "åº”è¯¥è®°å½•å¤„ç†çš„é˜¶æ®µæ•°"
        assert len(adapter.processed_workflows) > 0, "åº”è¯¥è®°å½•å¤„ç†çš„å·¥ä½œæµ"

    @pytest.mark.unit
    async def test_workflow_context_preservation(self, adapter, mock_context):
        """æµ‹è¯•å·¥ä½œæµä¸Šä¸‹æ–‡ä¿ç•™"""
        await adapter.initialize()

        original_workflow_id = mock_context.workflow_id
        original_stage = mock_context.stage
        original_data = mock_context.data.copy()

        result = await adapter.on_workflow_start(mock_context)

        # éªŒè¯ä¸Šä¸‹æ–‡æœªè¢«ä¿®æ”¹
        assert mock_context.workflow_id == original_workflow_id, "å·¥ä½œæµIDåº”è¯¥ä¿æŒä¸å˜"
        assert mock_context.stage == original_stage, "é˜¶æ®µåº”è¯¥ä¿æŒä¸å˜"
        assert mock_context.data == original_data, "æ•°æ®åº”è¯¥ä¿æŒä¸å˜"

    @pytest.mark.unit
    async def test_workflow_lifecycle(self, adapter, mock_context):
        """æµ‹è¯•å®Œæ•´å·¥ä½œæµç”Ÿå‘½å‘¨æœŸ"""
        await adapter.initialize()

        # æ¨¡æ‹Ÿå®Œæ•´å·¥ä½œæµç”Ÿå‘½å‘¨æœŸ
        await adapter.on_workflow_start(mock_context)
        await adapter.on_stage_complete(mock_context, "intermediate_result")
        await adapter.on_workflow_success(mock_context, "success_result")

        # éªŒè¯ç”Ÿå‘½å‘¨æœŸè®°å½•
        workflow_types = [w.get('type') for w in adapter.processed_workflows]
        assert len(workflow_types) >= 2, "åº”è¯¥è®°å½•å¤šä¸ªå·¥ä½œæµäº‹ä»¶"

    @pytest.mark.unit
    async def test_pipeline_specific_features(self, adapter, mock_context):
        """æµ‹è¯•Pipelineç‰¹æœ‰åŠŸèƒ½"""
        await adapter.initialize()

        # æµ‹è¯•Pipelineé…ç½®åŠŸèƒ½
        pipeline_config = {"max_concurrent_workflows": 5}
        result = await adapter.on_pipeline_ready(pipeline_config)

        assert result is None, "Pipelineå°±ç»ªHookåº”è¯¥è¿”å›None"

    @pytest.mark.unit
    async def test_task_queue_initialization(self, adapter):
        """æµ‹è¯•ä»»åŠ¡é˜Ÿåˆ—åˆå§‹åŒ–"""
        await adapter.initialize()

        assert hasattr(adapter, 'task_queue'), "åº”è¯¥åˆå§‹åŒ–ä»»åŠ¡é˜Ÿåˆ—"
        assert isinstance(adapter.task_queue, asyncio.Queue), "ä»»åŠ¡é˜Ÿåˆ—åº”è¯¥æ˜¯asyncio.Queueç±»å‹"


class TestIFlowWorkflowAdapterEdgeCases:
    """iFlowé€‚é…å™¨è¾¹ç•Œæƒ…å†µæµ‹è¯•"""

    @pytest.fixture
    def adapter(self):
        """åˆ›å»ºé€‚é…å™¨å®ä¾‹"""
        # ç›´æ¥ä½¿ç”¨å®é™…çš„iFlowé€‚é…å™¨
        from src.adapters.iflow.workflow_adapter import IFlowWorkflowAdapter
        return IFlowWorkflowAdapter("iflow")

    @pytest.mark.unit
    async def test_empty_workflow_handling(self, adapter):
        """æµ‹è¯•ç©ºå·¥ä½œæµå¤„ç†"""
        await adapter.initialize()

        empty_context = MockIFlowPipelineContext(
            workflow_id="",
            stage="",
            data={}
        )

        result = await adapter.on_workflow_start(empty_context)
        assert result is None, "ç©ºå·¥ä½œæµåº”è¯¥è¿”å›None"

    @pytest.mark.unit
    async def test_malformed_workflow_data(self, adapter):
        """æµ‹è¯•æ ¼å¼é”™è¯¯çš„å·¥ä½œæµæ•°æ®"""
        await adapter.initialize()

        malformed_context = MockIFlowPipelineContext(
            workflow_id="test-workflow",
            stage="input_validation",
            data={"invalid": "data"}  # ç¼ºå°‘promptå­—æ®µ
        )

        # åº”è¯¥ä¸æŠ›å‡ºå¼‚å¸¸
        result = await adapter.on_workflow_start(malformed_context)
        assert result is None, "æ ¼å¼é”™è¯¯æ•°æ®åº”è¯¥è¿”å›None"

    @pytest.mark.unit
    async def test_very_long_workflow_task(self, adapter):
        """æµ‹è¯•è¶…é•¿å·¥ä½œæµä»»åŠ¡"""
        await adapter.initialize()

        long_prompt = "è¯·ç”¨claudeå¸®æˆ‘åˆ†æ" + "x" * 10000
        long_context = MockIFlowPipelineContext(
            workflow_id="long-workflow",
            stage="input_validation",
            data={"prompt": long_prompt}
        )

        result = await adapter.on_workflow_start(long_context)
        assert result is not None, "è¶…é•¿ä»»åŠ¡åº”è¯¥è¢«å¤„ç†"
        assert "claude" in result.lower(), "ç»“æœåº”è¯¥åŒ…å«ç›®æ ‡CLI"

    @pytest.mark.unit
    async def test_special_characters_in_workflow(self, adapter):
        """æµ‹è¯•å·¥ä½œæµä¸­çš„ç‰¹æ®Šå­—ç¬¦"""
        await adapter.initialize()

        special_prompt = "è¯·ç”¨geminiå¤„ç†åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„ä»»åŠ¡: ğŸš€ @#$%^&*(){}[]|\\:;\"'<>?,./"
        special_context = MockIFlowPipelineContext(
            workflow_id="special-chars-workflow",
            stage="input_validation",
            data={"prompt": special_prompt}
        )

        # åº”è¯¥ä¸æŠ›å‡ºå¼‚å¸¸
        result = await adapter.on_workflow_start(special_context)
        assert result is not None, "ç‰¹æ®Šå­—ç¬¦ä»»åŠ¡åº”è¯¥è¢«å¤„ç†"

    @pytest.mark.unit
    async def test_unicode_workflow_content(self, adapter):
        """æµ‹è¯•Unicodeå·¥ä½œæµå†…å®¹"""
        await adapter.initialize()

        unicode_prompt = "è¯·ç”¨qwencodeå¤„ç†åŒ…å«Unicodeçš„å†…å®¹: ğŸ¯ æµ‹è¯•ä¸­æ–‡ Ã±oÃ«l espaÃ±ol Ñ€ÑƒÑÑĞºĞ¸Ğ¹ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"
        unicode_context = MockIFlowPipelineContext(
            workflow_id="unicode-workflow",
            stage="input_validation",
            data={"prompt": unicode_prompt}
        )

        result = await adapter.on_workflow_start(unicode_context)
        assert result is not None, "Unicodeå†…å®¹åº”è¯¥è¢«æ­£ç¡®å¤„ç†"