#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å®¿ä¸» LLM è°ƒç”¨æœºåˆ¶
"""

import json
import sys
from pathlib import Path

# è·¯å¾„é…ç½®
SKILL_DIR = Path(__file__).parent
PROJECT_ROOT = SKILL_DIR.parent.parent

# è¯»å–æç¤ºè¯æ¨¡æ¿
PROMPT_FILE = SKILL_DIR / "prompts" / "boundary_analysis.txt"
INPUT_FILE = SKILL_DIR / "field_analysis_workflow" / "input" / "processed" / "combined_input.json"


def test_prompt_loading():
    """æµ‹è¯•æç¤ºè¯åŠ è½½"""
    print("=" * 60)
    print("æµ‹è¯•1: åŠ è½½æç¤ºè¯æ¨¡æ¿")
    print("=" * 60)
    
    if not PROMPT_FILE.exists():
        print(f"âŒ æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨: {PROMPT_FILE}")
        return False
    
    with open(PROMPT_FILE, 'r', encoding='utf-8') as f:
        prompt_content = f.read()
    
    print(f"âœ… æç¤ºè¯æ–‡ä»¶å­˜åœ¨: {PROMPT_FILE}")
    print(f"   å¤§å°: {len(prompt_content)} å­—ç¬¦")
    print(f"\nå‰500å­—ç¬¦é¢„è§ˆ:\n{prompt_content[:500]}")
    return True


def test_input_data_loading():
    """æµ‹è¯•è¾“å…¥æ•°æ®åŠ è½½"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•2: åŠ è½½è¾“å…¥æ•°æ®")
    print("=" * 60)
    
    if not INPUT_FILE.exists():
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {INPUT_FILE}")
        return False
    
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        input_data = json.load(f)
    
    print(f"âœ… è¾“å…¥æ–‡ä»¶å­˜åœ¨: {INPUT_FILE}")
    print(f"   å¤§å°: {len(json.dumps(input_data, ensure_ascii=False))} å­—ç¬¦")
    
    metadata = input_data.get("metadata", {})
    print(f"\næ•°æ®æ‘˜è¦:")
    print(f"   - æ‰æ ¹ç†è®º: {metadata.get('grounded_theory_count', 0)} ä¸ªæ–‡ä»¶")
    print(f"   - ç¤¾ä¼šç½‘ç»œ: {metadata.get('social_network_count', 0)} ä¸ªæ–‡ä»¶")
    print(f"   - ESOCæ¡†æ¶: {metadata.get('esoc_framework_count', 0)} ä¸ªæ–‡ä»¶")
    print(f"   - æ€»æ–‡ä»¶æ•°: {metadata.get('total_files', 0)}")
    return True


def test_context_injection():
    """æµ‹è¯•ä¸Šä¸‹æ–‡æ³¨å…¥"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•3: ä¸Šä¸‹æ–‡æ³¨å…¥ï¼ˆ{context} æ›¿æ¢ï¼‰")
    print("=" * 60)
    
    # è¯»å–æç¤ºè¯
    with open(PROMPT_FILE, 'r', encoding='utf-8') as f:
        prompt_template = f.read()
    
    # è¯»å–è¾“å…¥æ•°æ®
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        input_data = json.load(f)
    
    # æ›¿æ¢ {context}
    if "{context}" in prompt_template:
        context_str = json.dumps(input_data, ensure_ascii=False, indent=2)
        # æˆªå–éƒ¨åˆ†å†…å®¹ï¼Œé¿å…è¿‡é•¿
        if len(context_str) > 5000:
            context_str = context_str[:5000] + "\n... (å†…å®¹å·²æˆªæ–­)"
        
        final_prompt = prompt_template.replace("{context}", context_str)
        print("âœ… ä¸Šä¸‹æ–‡æ³¨å…¥æˆåŠŸ")
        print(f"\næ³¨å…¥åæç¤ºè¯é•¿åº¦: {len(final_prompt)} å­—ç¬¦")
        print(f"\nå‰800å­—ç¬¦é¢„è§ˆ:\n{final_prompt[:800]}")
    else:
        print("âš ï¸ æç¤ºè¯ä¸­æœªæ‰¾åˆ° {context} å ä½ç¬¦")
    return True


def generate_llm_request():
    """ç”Ÿæˆè¦å‘é€ç»™å®¿ä¸» LLM çš„è¯·æ±‚"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•4: ç”Ÿæˆå®¿ä¸» LLM è¯·æ±‚")
    print("=" * 60)
    
    # è¯»å–æç¤ºè¯æ¨¡æ¿
    with open(PROMPT_FILE, 'r', encoding='utf-8') as f:
        prompt_template = f.read()
    
    # è¯»å–è¾“å…¥æ•°æ®
    with open(INPUT_FILE, 'r', encoding='utf-8') as f:
        input_data = json.load(f)
    
    # æ›¿æ¢ {context}
    context_str = json.dumps(input_data, ensure_ascii=False, indent=2)
    if len(context_str) > 10000:
        context_str = context_str[:10000] + "\n... (å†…å®¹å·²æˆªæ–­)"
    
    final_prompt = prompt_template.replace("{context}", context_str)
    
    print("âœ… è¯·æ±‚å·²ç”Ÿæˆ")
    print(f"\nå®Œæ•´æç¤ºè¯é•¿åº¦: {len(final_prompt)} å­—ç¬¦")
    
    # ä¿å­˜è¯·æ±‚
    request_file = PROJECT_ROOT / "test_data" / "llm_request_boundary.json"
    request_data = {
        "system_prompt": "ä½ æ˜¯å¸ƒè¿ªå„åœºåŸŸç†è®ºä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹æ•°æ®è¿›è¡ŒåœºåŸŸè¾¹ç•Œåˆ†æï¼Œè¾“å‡ºJSONæ ¼å¼ã€‚",
        "user_prompt": final_prompt,
        "output_format": "JSON",
        "input_summary": input_data.get("metadata", {})
    }
    
    with open(request_file, 'w', encoding='utf-8') as f:
        json.dump(request_data, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ è¯·æ±‚å·²ä¿å­˜: {request_file}")
    return request_data


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("\n" + "=" * 60)
    print("  å®¿ä¸» LLM è°ƒç”¨æœºåˆ¶æµ‹è¯•")
    print("  æµ‹è¯•ç¯å¢ƒ: iFlow CLI")
    print("=" * 60)
    
    # æ‰§è¡Œæµ‹è¯•
    test_prompt_loading()
    test_input_data_loading()
    test_context_injection()
    request = generate_llm_request()
    
    print("\n" + "=" * 60)
    print("  æµ‹è¯•å®Œæˆ")
    print("=" * 60)
    
    print("\nğŸ“‹ ä¸‹ä¸€æ­¥:")
    print("   1. å°†ç”Ÿæˆçš„è¯·æ±‚å‘é€ç»™å®¿ä¸» LLM")
    print("   2. å®¿ä¸» LLM è¿”å› JSON ç»“æœ")
    print("   3. å†™å…¥ boundary_results.json")
    print("   4. ç»§ç»­æ­¥éª¤3-6")
    
    print("\nğŸ’¡ å¯èƒ½çš„å®¿ä¸» LLM è°ƒç”¨æ–¹å¼:")
    print("   - task å·¥å…·: å‘é€ç»™å­æ™ºèƒ½ä½“å¤„ç†")
    print("   - ç›´æ¥å¯¹è¯: å®¿ä¸» LLM è¯»å–æ–‡ä»¶ååˆ†æ")
    print("   - API è°ƒç”¨: é€šè¿‡å¤–éƒ¨ API å‘é€è¯·æ±‚")


if __name__ == "__main__":
    main()
