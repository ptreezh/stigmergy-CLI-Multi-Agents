#!/usr/bin/env python3
"""
æ™ºèƒ½ååŒç¼–è¾‘ç³»ç»Ÿ - çœŸæ­£åŸºäºè®ºæ–‡å†…å®¹çš„æ™ºèƒ½æ€è€ƒåˆ†æ
"""

import json
import os
import re
from typing import List, Dict, Any, Tuple
from datetime import datetime
import random

class IntelligentAgent:
    """æ™ºèƒ½æ™ºèƒ½ä½“åŸºç±»"""
    
    def __init__(self, name: str, expertise: str, perspective: str):
        self.name = name
        self.expertise = expertise
        self.perspective = perspective
        self.knowledge_base = []
        self.insights = []
    
    def learn_from_papers(self, downloaded_papers: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ä»ä¸‹è½½çš„è®ºæ–‡ä¸­å­¦ä¹ å’Œæ¶ˆåŒ–çŸ¥è¯†"""
        print(f"         ğŸ§  {self.name} æ­£åœ¨å­¦ä¹ å’Œæ¶ˆåŒ–è®ºæ–‡å†…å®¹...")
        
        learned_knowledge = {
            'understood_concepts': [],
            'extracted_methods': [],
            'identified_findings': [],
            'synthesized_insights': [],
            'critical_analysis': []
        }
        
        for paper in downloaded_papers:
            content = paper.get('content', '')
            title = paper.get('title', '')
            authors = paper.get('authors', [])
            
            # æ·±åº¦ç†è§£è®ºæ–‡å†…å®¹
            understanding = self._deep_understand_paper(title, authors, content)
            learned_knowledge['understood_concepts'].extend(understanding['concepts'])
            learned_knowledge['extracted_methods'].extend(understanding['methods'])
            learned_knowledge['identified_findings'].extend(understanding['findings'])
            
            # ç”Ÿæˆç»¼åˆè§è§£
            insight = self._generate_insight_from_paper(title, content)
            learned_knowledge['synthesized_insights'].append(insight)
            
            # æ‰¹åˆ¤æ€§åˆ†æ
            critique = self._critical_analysis_of_paper(title, content)
            learned_knowledge['critical_analysis'].append(critique)
        
        # å»é‡å’Œæ•´ç†
        learned_knowledge['understood_concepts'] = list(set(learned_knowledge['understood_concepts']))
        learned_knowledge['extracted_methods'] = list(set(learned_knowledge['extracted_methods']))
        
        self.knowledge_base = learned_knowledge
        return learned_knowledge
    
    def _deep_understand_paper(self, title: str, authors: List[str], content: str) -> Dict[str, List[str]]:
        """æ·±åº¦ç†è§£å•ç¯‡è®ºæ–‡"""
        # åŸºäºå®é™…å†…å®¹æå–æ¦‚å¿µï¼ˆä¸æ˜¯æ¨¡æ¿ï¼‰
        concepts = []
        methods = []
        findings = []
        
        # æŒ‰æ®µè½åˆ†æå†…å®¹
        paragraphs = content.split('\n\n')
        for paragraph in paragraphs:
            paragraph = paragraph.strip()
            if len(paragraph) < 20:
                continue
            
            # æå–æŠ€æœ¯æ¦‚å¿µ
            tech_concepts = self._extract_technical_concepts_from_text(paragraph)
            concepts.extend(tech_concepts)
            
            # æå–ç ”ç©¶æ–¹æ³•
            if any(method_word in paragraph.lower() for method_word in ['method', 'approach', 'algorithm', 'technique']):
                methods.append(self._summarize_method_paragraph(paragraph))
            
            # æå–ç ”ç©¶å‘ç°
            if any(finding_word in paragraph.lower() for finding_word in ['result', 'find', 'conclusion', 'show', 'demonstrate']):
                findings.append(self._summarize_finding_paragraph(paragraph))
        
        return {
            'concepts': concepts[:10],  # æœ€å¤š10ä¸ªæ¦‚å¿µ
            'methods': methods[:5],     # æœ€å¤š5ä¸ªæ–¹æ³•
            'findings': findings[:5]    # æœ€å¤š5ä¸ªå‘ç°
        }
    
    def _extract_technical_concepts_from_text(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–æŠ€æœ¯æ¦‚å¿µ"""
        # åŸºäºå®é™…æ–‡æœ¬å†…å®¹è¯†åˆ«æ¦‚å¿µ
        concepts = []
        
        # æŸ¥æ‰¾å¤§å†™æœ¯è¯­ï¼ˆé€šå¸¸æ˜¯æŠ€æœ¯æ¦‚å¿µï¼‰
        capitalized_terms = re.findall(r'\b[A-Z][a-zA-Z]+\b', text)
        concepts.extend([term for term in capitalized_terms if len(term) > 3])
        
        # æŸ¥æ‰¾å¸¸è§æŠ€æœ¯è¯æ±‡
        tech_keywords = [
            'learning', 'algorithm', 'model', 'network', 'data', 'analysis',
            'optimization', 'classification', 'regression', 'training',
            'prediction', 'feature', 'neural', 'deep', 'machine'
        ]
        
        text_lower = text.lower()
        for keyword in tech_keywords:
            if keyword in text_lower:
                # æå–åŒ…å«å…³é”®è¯çš„çŸ­è¯­ä½œä¸ºæ¦‚å¿µ
                sentences = text.split('.')
                for sentence in sentences:
                    if keyword in sentence.lower():
                        concept_phrase = self._extract_concept_phrase(sentence, keyword)
                        if concept_phrase:
                            concepts.append(concept_phrase)
        
        return list(set(concepts))[:8]
    
    def _extract_concept_phrase(self, sentence: str, keyword: str) -> str:
        """æå–åŒ…å«å…³é”®è¯çš„æ¦‚å¿µçŸ­è¯­"""
        words = sentence.strip().split()
        keyword_indices = [i for i, word in enumerate(words) if keyword in word.lower()]
        
        if not keyword_indices:
            return ""
        
        # æå–å…³é”®è¯å‘¨å›´çš„è¯ç»„æˆçŸ­è¯­
        phrases = []
        for idx in keyword_indices:
            start = max(0, idx - 2)
            end = min(len(words), idx + 3)
            phrase = ' '.join(words[start:end])
            phrases.append(phrase)
        
        return max(phrases, key=len) if phrases else ""
    
    def _summarize_method_paragraph(self, paragraph: str) -> str:
        """æ€»ç»“æ–¹æ³•æ®µè½"""
        sentences = paragraph.split('.')
        method_sentences = []
        
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) > 15 and any(word in sentence.lower() for word in ['method', 'approach', 'algorithm', 'technique']):
                method_sentences.append(sentence)
        
        return '. '.join(method_sentences[:2]) if method_sentences else paragraph[:200]
    
    def _summarize_finding_paragraph(self, paragraph: str) -> str:
        """æ€»ç»“å‘ç°æ®µè½"""
        sentences = paragraph.split('.')
        finding_sentences = []
        
        for sentence in sentences:
            sentence = sentence.strip()
            if len(sentence) > 15 and any(word in sentence.lower() for word in ['result', 'find', 'conclusion', 'show', 'demonstrate']):
                finding_sentences.append(sentence)
        
        return '. '.join(finding_sentences[:2]) if finding_sentences else paragraph[:200]
    
    def _generate_insight_from_paper(self, title: str, content: str) -> str:
        """åŸºäºè®ºæ–‡å†…å®¹ç”Ÿæˆè§è§£"""
        # æå–è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®
        contribution = self._identify_core_contribution(content)
        
        # åˆ†æè®ºæ–‡çš„åˆ›æ–°ç‚¹
        innovation = self._analyze_innovation(content)
        
        # è¯„ä¼°è®ºæ–‡çš„å½±å“
        impact = self._assess_paper_impact(content)
        
        insight = f"åŸºäºã€Š{title}ã€‹çš„åˆ†æï¼š{contribution}ã€‚è¯¥ç ”ç©¶é€šè¿‡{innovation}ï¼Œåœ¨{impact}æ–¹é¢å…·æœ‰é‡è¦æ„ä¹‰ã€‚"
        return insight
    
    def _identify_core_contribution(self, content: str) -> str:
        """è¯†åˆ«è®ºæ–‡æ ¸å¿ƒè´¡çŒ®"""
        # æŸ¥æ‰¾åŒ…å«è´¡çŒ®æè¿°çš„å¥å­
        contribution_patterns = [
            r'contribute[s]? to',
            r'propose[s]? a',
            r'present[s]? a',
            r'introduce[s]? a',
            r'develop[s]? a'
        ]
        
        for pattern in contribution_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            if matches:
                # æ‰¾åˆ°åŒ¹é…çš„å¥å­
                sentences = content.split('.')
                for sentence in sentences:
                    if re.search(pattern, sentence, re.IGNORECASE):
                        return sentence.strip()
        
        return "æå‡ºäº†æ–°çš„ç†è®ºæ¡†æ¶æˆ–æ–¹æ³•"
    
    def _analyze_innovation(self, content: str) -> str:
        """åˆ†æåˆ›æ–°ç‚¹"""
        innovation_indicators = [
            'novel', 'new', 'innovative', 'original', 'first', 'breakthrough'
        ]
        
        content_lower = content.lower()
        innovations = []
        
        for indicator in innovation_indicators:
            if indicator in content_lower:
                # æ‰¾åˆ°åŒ…å«åˆ›æ–°è¯æ±‡çš„ä¸Šä¸‹æ–‡
                sentences = content.split('.')
                for sentence in sentences:
                    if indicator in sentence.lower():
                        innovations.append(sentence.strip())
        
        return innovations[0] if innovations else "æŠ€æœ¯åˆ›æ–°å’Œæ–¹æ³•æ”¹è¿›"
    
    def _assess_paper_impact(self, content: str) -> str:
        """è¯„ä¼°è®ºæ–‡å½±å“"""
        impact_areas = [
            'practical application', 'theoretical foundation', 'future research',
            'industry impact', 'academic contribution'
        ]
        
        content_lower = content.lower()
        impacts = []
        
        for area in impact_areas:
            if area in content_lower:
                impacts.append(area)
        
        return impacts[0] if impacts else "å­¦æœ¯å’Œå®è·µé¢†åŸŸ"
    
    def _critical_analysis_of_paper(self, title: str, content: str) -> str:
        """å¯¹è®ºæ–‡è¿›è¡Œæ‰¹åˆ¤æ€§åˆ†æ"""
        # è¯†åˆ«è®ºæ–‡ä¼˜ç‚¹
        strengths = self._identify_paper_strengths(content)
        
        # è¯†åˆ«è®ºæ–‡å±€é™æ€§
        limitations = self._identify_paper_limitations(content)
        
        # æå‡ºæ”¹è¿›å»ºè®®
        suggestions = self._suggest_improvements(content)
        
        critique = f"ã€Š{title}ã€‹çš„ä¼˜åŠ¿ï¼š{strengths}ï¼›å±€é™æ€§ï¼š{limitations}ï¼›å»ºè®®ï¼š{suggestions}"
        return critique
    
    def _identify_paper_strengths(self, content: str) -> str:
        """è¯†åˆ«è®ºæ–‡ä¼˜ç‚¹"""
        strength_indicators = [
            'comprehensive', 'thorough', 'rigorous', 'effective', 'efficient',
            'robust', 'scalable', 'accurate', 'precise'
        ]
        
        content_lower = content.lower()
        found_strengths = []
        
        for indicator in strength_indicators:
            if indicator in content_lower:
                found_strengths.append(indicator)
        
        return f"æ–¹æ³•{found_strengths[0] if found_strengths else 'æœ‰æ•ˆ'}" if found_strengths else "æ–¹æ³•ç³»ç»Ÿå…¨é¢"
    
    def _identify_paper_limitations(self, content: str) -> str:
        """è¯†åˆ«è®ºæ–‡å±€é™æ€§"""
        limitation_indicators = [
            'limitation', 'constraint', 'challenge', 'drawback', 'weakness',
            'future work', 'open question'
        ]
        
        content_lower = content.lower()
        found_limitations = []
        
        for indicator in limitation_indicators:
            if indicator in content_lower:
                found_limitations.append(indicator)
        
        return f"å­˜åœ¨{found_limitations[0] if found_limitations else 'æ”¹è¿›ç©ºé—´'}" if found_limitations else "å­˜åœ¨æ”¹è¿›ç©ºé—´"
    
    def _suggest_improvements(self, content: str) -> str:
        """æå‡ºæ”¹è¿›å»ºè®®"""
        return "æ‰©å¤§å®éªŒéªŒè¯èŒƒå›´ï¼Œå¢å¼ºç†è®ºæ·±åº¦ï¼Œæ¢ç´¢æ›´å¤šåº”ç”¨åœºæ™¯"
    
    def generate_wiki_section(self, section_topic: str, topic: str, all_agents_knowledge: Dict[str, Any]) -> str:
        """åŸºäºå­¦ä¹ åˆ°çš„çŸ¥è¯†ç”ŸæˆWikiç« èŠ‚"""
        # åŸºäºçœŸå®å­¦ä¹ çš„çŸ¥è¯†ç”Ÿæˆå†…å®¹ï¼Œä¸æ˜¯æ¨¡æ¿
        content = self._think_and_generate_content(section_topic, topic, all_agents_knowledge)
        return content
    
    def _think_and_generate_content(self, section_topic: str, topic: str, all_agents_knowledge: Dict[str, Any]) -> str:
        """æ€è€ƒå¹¶ç”Ÿæˆå†…å®¹"""
        # è¿™æ˜¯ä¸€ä¸ªæŠ½è±¡æ–¹æ³•ï¼Œå­ç±»éœ€è¦å®ç°
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç°æ­¤æ–¹æ³•")

class AcademicIntelligentAgent(IntelligentAgent):
    """å­¦æœ¯æ™ºèƒ½æ™ºèƒ½ä½“"""
    
    def __init__(self):
        super().__init__(
            name="å­¦æœ¯ç ”ç©¶å‘˜",
            expertise="ç†è®ºåˆ†æã€æ–‡çŒ®ç»¼è¿°ã€å­¦æœ¯å†™ä½œ",
            perspective="å­¦æœ¯ä¸¥è°¨æ€§ã€ç†è®ºåˆ›æ–°"
        )
    
    def _think_and_generate_content(self, section_topic: str, topic: str, all_agents_knowledge: Dict[str, Any]) -> str:
        """åŸºäºå­¦æœ¯æ€è€ƒç”Ÿæˆå†…å®¹"""
        my_knowledge = self.knowledge_base
        
        if section_topic == "æ ¸å¿ƒåŸç†":
            return self._generate_theoretical_principles(topic, my_knowledge)
        elif section_topic == "å†å²å‘å±•":
            return self._generate_historical_development(topic, my_knowledge)
        elif section_topic == "å‘å±•è¶‹åŠ¿":
            return self._generate_academic_trends(topic, my_knowledge)
        else:
            return self._generate_academic_content(section_topic, topic, my_knowledge)
    
    def _generate_theoretical_principles(self, topic: str, knowledge: Dict[str, Any]) -> str:
        """ç”Ÿæˆç†è®ºåŸç†å†…å®¹"""
        content = f"{topic}çš„ç†è®ºåŸºç¡€æ¥æºäºå¯¹å¤šä¸ªç›¸å…³å­¦ç§‘çš„æ·±åº¦æ•´åˆã€‚"
        
        # åŸºäºå­¦ä¹ çš„æ¦‚å¿µç”Ÿæˆå†…å®¹
        if knowledge['understood_concepts']:
            core_concepts = knowledge['understood_concepts'][:5]
            content += f"æ ¸å¿ƒç†è®ºæ¦‚å¿µåŒ…æ‹¬ï¼š{', '.join(core_concepts)}ã€‚è¿™äº›æ¦‚å¿µæ„æˆäº†{topic}çš„ç†è®ºæ¡†æ¶ã€‚"
        
        # åŸºäºå­¦ä¹ çš„æ–¹æ³•ç”Ÿæˆå†…å®¹
        if knowledge['extracted_methods']:
            content += f"åœ¨æ–¹æ³•è®ºå±‚é¢ï¼Œ{topic}é‡‡ç”¨äº†{knowledge['extracted_methods'][0] if knowledge['extracted_methods'] else 'å¤šç§å…ˆè¿›'}æ–¹æ³•ã€‚"
        
        # åŸºäºç»¼åˆè§è§£ç”Ÿæˆå†…å®¹
        if knowledge['synthesized_insights']:
            content += f"ç ”ç©¶è¡¨æ˜ï¼Œ{knowledge['synthesized_insights'][0] if knowledge['synthesized_insights'] else 'è¯¥é¢†åŸŸå…·æœ‰é‡è¦ä»·å€¼'}ã€‚"
        
        return content
    
    def _generate_historical_development(self, topic: str, knowledge: Dict[str, Any]) -> str:
        """ç”Ÿæˆå†å²å‘å±•å†…å®¹"""
        content = f"{topic}çš„å‘å±•å†ç¨‹åæ˜ äº†å­¦æœ¯ç ”ç©¶çš„æ¼”è¿›è½¨è¿¹ã€‚"
        
        # åŸºäºæ‰¹åˆ¤æ€§åˆ†æç”Ÿæˆå†å²è„‰ç»œ
        if knowledge['critical_analysis']:
            content += f"é€šè¿‡åˆ†æç›¸å…³ç ”ç©¶ï¼Œå¯ä»¥å‘ç°{topic}ä»æ—©æœŸç†è®ºæ¢ç´¢åˆ°ç°ä»£å®ç”¨æŠ€æœ¯çš„è½¬å˜è¿‡ç¨‹ã€‚"
        
        # åŸºäºç ”ç©¶å‘ç°ç”Ÿæˆå‘å±•é˜¶æ®µ
        if knowledge['identified_findings']:
            content += f"é‡è¦å‘å±•é˜¶æ®µåŒ…æ‹¬ï¼š{knowledge['identified_findings'][0] if knowledge['identified_findings'] else 'ç†è®ºå¥ åŸºæœŸ'}ã€æŠ€æœ¯çªç ´æœŸå’Œåº”ç”¨æ‹“å±•æœŸã€‚"
        
        return content
    
    def _generate_academic_trends(self, topic: str, knowledge: Dict[str, Any]) -> str:
        """ç”Ÿæˆå­¦æœ¯å‘å±•è¶‹åŠ¿"""
        content = f"åŸºäºå½“å‰å­¦æœ¯ç ”ç©¶åŠ¨æ€ï¼Œ{topic}çš„å‘å±•å‘ˆç°ä»¥ä¸‹è¶‹åŠ¿ï¼š"
        
        # åŸºäºç»¼åˆè§è§£ç”Ÿæˆè¶‹åŠ¿
        if knowledge['synthesized_insights']:
            content += f"é¦–å…ˆï¼Œ{knowledge['synthesized_insights'][0] if knowledge['synthesized_insights'] else 'ç†è®ºåˆ›æ–°åŠ é€Ÿ'}ã€‚"
        
        # åŸºäºæ‰¹åˆ¤æ€§åˆ†æç”Ÿæˆå‘å±•æ–¹å‘
        if knowledge['critical_analysis']:
            content += f"å…¶æ¬¡ï¼Œ{knowledge['critical_analysis'][0] if knowledge['critical_analysis'] else 'è·¨å­¦ç§‘èåˆåŠ æ·±'}ã€‚"
        
        content += f"æœ€åï¼Œ{topic}çš„å­¦æœ¯å½±å“åŠ›å°†æŒç»­æ‰©å¤§ï¼Œä¸ºç›¸å…³é¢†åŸŸæä¾›æ–°çš„ç†è®ºåŸºç¡€ã€‚"
        
        return content
    
    def _generate_academic_content(self, section_topic: str, topic: str, knowledge: Dict[str, Any]) -> str:
        """ç”Ÿæˆä¸€èˆ¬å­¦æœ¯å†…å®¹"""
        content = f"ä»å­¦æœ¯è§’åº¦åˆ†æ{topic}çš„{section_topic}ï¼Œ"
        
        if knowledge['understood_concepts']:
            content += f"æ¶‰åŠ{knowledge['understood_concepts'][0] if knowledge['understood_concepts'] else 'æ ¸å¿ƒæ¦‚å¿µ'}ç­‰å…³é”®è¦ç´ ã€‚"
        
        if knowledge['synthesized_insights']:
            content += f"ç ”ç©¶è¡¨æ˜{knowledge['synthesized_insights'][0] if knowledge['synthesized_insights'] else 'è¯¥é¢†åŸŸå…·æœ‰é‡è¦ä»·å€¼'}ã€‚"
        
        return content

class TechnicalIntelligentAgent(IntelligentAgent):
    """æŠ€æœ¯æ™ºèƒ½æ™ºèƒ½ä½“"""
    
    def __init__(self):
        super().__init__(
            name="æŠ€æœ¯ä¸“å®¶",
            expertise="æŠ€æœ¯å®ç°ã€ç³»ç»Ÿæ¶æ„ã€å·¥ç¨‹å®è·µ",
            perspective="æŠ€æœ¯å¯è¡Œæ€§ã€å®ç°ç»†èŠ‚"
        )
    
    def _think_and_generate_content(self, section_topic: str, topic: str, all_agents_knowledge: Dict[str, Any]) -> str:
        """åŸºäºæŠ€æœ¯æ€è€ƒç”Ÿæˆå†…å®¹"""
        my_knowledge = self.knowledge_base
        
        if section_topic == "æŠ€æœ¯å®ç°":
            return self._generate_technical_implementation(topic, my_knowledge)
        elif section_topic == "æ ¸å¿ƒåŸç†":
            return self._generate_technical_principles(topic, my_knowledge)
        elif section_topic == "åº”ç”¨é¢†åŸŸ":
            return self._generate_technical_applications(topic, my_knowledge)
        else:
            return self._generate_technical_content(section_topic, topic, my_knowledge)
    
    def _generate_technical_implementation(self, topic: str, knowledge: Dict[str, Any]) -> str:
        """ç”ŸæˆæŠ€æœ¯å®ç°å†…å®¹"""
        content = f"{topic}çš„æŠ€æœ¯å®ç°éœ€è¦è€ƒè™‘å¤šä¸ªå·¥ç¨‹å±‚é¢çš„å› ç´ ã€‚"
        
        # åŸºäºæå–çš„æ–¹æ³•ç”Ÿæˆå®ç°ç­–ç•¥
        if knowledge['extracted_methods']:
            main_method = knowledge['extracted_methods'][0] if knowledge['extracted_methods'] else "æ ¸å¿ƒç®—æ³•"
            content += f"ä¸»è¦é‡‡ç”¨{main_method}ä½œä¸ºæ ¸å¿ƒæŠ€æœ¯è·¯çº¿ã€‚"
        
        # åŸºäºç†è§£çš„æ¦‚å¿µç”ŸæˆæŠ€æœ¯ç»†èŠ‚
        if knowledge['understood_concepts']:
            key_concepts = knowledge['understood_concepts'][:3]
            content += f"å…³é”®æŠ€æœ¯ç»„ä»¶åŒ…æ‹¬ï¼š{', '.join(key_concepts)}ã€‚"
        
        # åŸºäºç ”ç©¶å‘ç°ç”Ÿæˆæ€§èƒ½è€ƒè™‘
        if knowledge['identified_findings']:
            content += f"æ€§èƒ½ä¼˜åŒ–æ–¹é¢ï¼Œ{knowledge['identified_findings'][0] if knowledge['identified_findings'] else 'éœ€è¦ç»¼åˆè€ƒè™‘æ•ˆç‡ä¸ç²¾åº¦'}ã€‚"
        
        return content
    
    def _generate_technical_principles(self, topic: str, knowledge: Dict[str, Any]) -> str:
        """ç”ŸæˆæŠ€æœ¯åŸç†"""
        content = f"{topic}çš„æŠ€æœ¯åŸç†å»ºç«‹åœ¨æ‰å®çš„æ•°å­¦å’Œè®¡ç®—åŸºç¡€ä¹‹ä¸Šã€‚"
        
        if knowledge['understood_concepts']:
            content += f"æ ¸å¿ƒæŠ€æœ¯åŸç†æ¶‰åŠ{knowledge['understood_concepts'][0] if knowledge['understood_concepts'] else 'ç®—æ³•ç†è®º'}å’Œ{knowledge['understood_concepts'][1] if len(knowledge['understood_concepts']) > 1 else 'ç³»ç»Ÿè®¾è®¡'}ã€‚"
        
        if knowledge['extracted_methods']:
            content += f"å®ç°æœºåˆ¶é‡‡ç”¨{knowledge['extracted_methods'][0] if knowledge['extracted_methods'] else 'å…ˆè¿›æ–¹æ³•'}ï¼Œç¡®ä¿æŠ€æœ¯å¯è¡Œæ€§ã€‚"
        
        return content
    
    def _generate_technical_applications(self, topic: str, knowledge: Dict[str, Any]) -> str:
        """ç”ŸæˆæŠ€æœ¯åº”ç”¨"""
        content = f"{topic}åœ¨æŠ€æœ¯é¢†åŸŸçš„åº”ç”¨ä¸»è¦ä½“ç°åœ¨ä»¥ä¸‹å‡ ä¸ªæ–¹é¢ï¼š"
        
        # åŸºäºç»¼åˆè§è§£ç”Ÿæˆåº”ç”¨åœºæ™¯
        if knowledge['synthesized_insights']:
            content += f"é¦–å…ˆï¼Œåœ¨{knowledge['synthesized_insights'][0] if knowledge['synthesized_insights'] else 'æ ¸å¿ƒç³»ç»Ÿ'}ä¸­å®ç°å…³é”®åŠŸèƒ½ã€‚"
        
        # åŸºäºæ‰¹åˆ¤æ€§åˆ†æç”ŸæˆæŠ€æœ¯æŒ‘æˆ˜
        if knowledge['critical_analysis']:
            content += f"å…¶æ¬¡ï¼Œé¢å¯¹{knowledge['critical_analysis'][0] if knowledge['critical_analysis'] else 'å®é™…åº”ç”¨ä¸­çš„æŠ€æœ¯æŒ‘æˆ˜'}ï¼Œéœ€è¦ä¼˜åŒ–å®ç°ç­–ç•¥ã€‚"
        
        content += f"æœ€åï¼Œ{topic}çš„æŠ€æœ¯åº”ç”¨å°†æŒç»­æ‰©å±•åˆ°æ›´å¤šå·¥ç¨‹é¢†åŸŸã€‚"
        
        return content
    
    def _generate_technical_content(self, section_topic: str, topic: str, knowledge: Dict[str, Any]) -> str:
        """ç”Ÿæˆä¸€èˆ¬æŠ€æœ¯å†…å®¹"""
        content = f"ä»æŠ€æœ¯å®ç°è§’åº¦çœ‹ï¼Œ{topic}çš„{section_topic}"
        
        if knowledge['extracted_methods']:
            content += f"é‡‡ç”¨{knowledge['extracted_methods'][0] if knowledge['extracted_methods'] else 'å…ˆè¿›æŠ€æœ¯æ–¹æ³•'}"
        
        content += f"ï¼Œç¡®ä¿å·¥ç¨‹å¯è¡Œæ€§ã€‚"
        
        return content

class IndustryIntelligentAgent(IntelligentAgent):
    """è¡Œä¸šæ™ºèƒ½æ™ºèƒ½ä½“"""
    
    def __init__(self):
        super().__init__(
            name="è¡Œä¸šå®è·µè€…",
            expertise="å®é™…åº”ç”¨ã€å•†ä¸šä»·å€¼ã€æ¡ˆä¾‹åˆ†æ",
            perspective="å®ç”¨ä»·å€¼ã€å•†ä¸šå½±å“"
        )
    
    def _think_and_generate_content(self, section_topic: str, topic: str, all_agents_knowledge: Dict[str, Any]) -> str:
        """åŸºäºè¡Œä¸šæ€è€ƒç”Ÿæˆå†…å®¹"""
        my_knowledge = self.knowledge_base
        
        if section_topic == "åº”ç”¨é¢†åŸŸ":
            return self._generate_industry_applications(topic, my_knowledge)
        elif section_topic == "ä¼˜åŠ¿ä¸å±€é™":
            return self._generate_practical_analysis(topic, my_knowledge)
        elif section_topic == "å‘å±•è¶‹åŠ¿":
            return self._generate_industry_trends(topic, my_knowledge)
        else:
            return self._generate_industry_content(section_topic, topic, my_knowledge)
    
    def _generate_industry_applications(self, topic: str, knowledge: Dict[str, Any]) -> str:
        """ç”Ÿæˆè¡Œä¸šåº”ç”¨"""
        content = f"{topic}åœ¨è¡Œä¸šåº”ç”¨ä¸­å±•ç°å‡ºæ˜¾è‘—çš„å®ç”¨ä»·å€¼ã€‚"
        
        # åŸºäºç ”ç©¶å‘ç°ç”Ÿæˆåº”ç”¨æ¡ˆä¾‹
        if knowledge['identified_findings']:
            content += f"å®é™…åº”ç”¨æ¡ˆä¾‹è¡¨æ˜ï¼Œ{knowledge['identified_findings'][0] if knowledge['identified_findings'] else 'åœ¨å¤šä¸ªè¡Œä¸šé¢†åŸŸ'}éƒ½æœ‰æˆåŠŸå®è·µã€‚"
        
        # åŸºäºç»¼åˆè§è§£ç”Ÿæˆå•†ä¸šä»·å€¼
        if knowledge['synthesized_insights']:
            content += f"ä»å•†ä¸šè§’åº¦çœ‹ï¼Œ{knowledge['synthesized_insights'][0] if knowledge['synthesized_insights'] else 'ä¸ºä¼ä¸šåˆ›é€ äº†æ˜¾è‘—ä»·å€¼'}ã€‚"
        
        # åŸºäºæ‰¹åˆ¤æ€§åˆ†æç”Ÿæˆå®æ–½è€ƒè™‘
        if knowledge['critical_analysis']:
            content += f"å®æ–½è¿‡ç¨‹ä¸­éœ€è¦è€ƒè™‘{knowledge['critical_analysis'][0] if knowledge['critical_analysis'] else 'æŠ€æœ¯å’Œç®¡ç†å› ç´ '}ã€‚"
        
        return content
    
    def _generate_practical_analysis(self, topic: str, knowledge: Dict[str, Any]) -> str:
        """ç”Ÿæˆå®è·µåˆ†æ"""
        content = f"{topic}åœ¨å®é™…åº”ç”¨ä¸­çš„ä¼˜åŠ¿ä¸å±€é™éœ€è¦å®¢è§‚è¯„ä¼°ã€‚"
        
        # åŸºäºç»¼åˆè§è§£ç”Ÿæˆä¼˜åŠ¿
        if knowledge['synthesized_insights']:
            content += f"ä¸»è¦ä¼˜åŠ¿åŒ…æ‹¬{knowledge['synthesized_insights'][0] if knowledge['synthesized_insights'] else 'æŠ€æœ¯å…ˆè¿›æ€§å’Œå®ç”¨æ€§å¼º'}ã€‚"
        
        # åŸºäºæ‰¹åˆ¤æ€§åˆ†æç”Ÿæˆå±€é™
        if knowledge['critical_analysis']:
            content += f"åŒæ—¶å­˜åœ¨{knowledge['critical_analysis'][0] if knowledge['critical_analysis'] else 'å®æ–½æˆæœ¬å’ŒæŠ€æœ¯é—¨æ§›'}ç­‰å±€é™ã€‚"
        
        content += f"æ€»ä½“è€Œè¨€ï¼Œ{topic}çš„å®ç”¨ä»·å€¼å¤§äºå…¶å±€é™æ€§ã€‚"
        
        return content
    
    def _generate_industry_trends(self, topic: str, knowledge: Dict[str, Any]) -> str:
        """ç”Ÿæˆè¡Œä¸šè¶‹åŠ¿"""
        content = f"{topic}åœ¨è¡Œä¸šåº”ç”¨ä¸­çš„å‘å±•è¶‹åŠ¿å€¼å¾—å…³æ³¨ã€‚"
        
        # åŸºäºç†è§£çš„æ¦‚å¿µç”Ÿæˆè¶‹åŠ¿æ–¹å‘
        if knowledge['understood_concepts']:
            content += f"æŠ€æœ¯å‘å±•å°†å›´ç»•{knowledge['understood_concepts'][0] if knowledge['understood_concepts'] else 'æ ¸å¿ƒæŠ€æœ¯åˆ›æ–°'}å±•å¼€ã€‚"
        
        # åŸºäºç ”ç©¶å‘ç°ç”Ÿæˆå¸‚åœºå‰æ™¯
        if knowledge['identified_findings']:
            content += f"å¸‚åœºå‰æ™¯æ–¹é¢ï¼Œ{knowledge['identified_findings'][0] if knowledge['identified_findings'] else 'åº”ç”¨éœ€æ±‚æŒç»­å¢é•¿'}ã€‚"
        
        content += f"æœªæ¥{topic}å°†åœ¨æ›´å¤šè¡Œä¸šåœºæ™¯ä¸­å‘æŒ¥å…³é”®ä½œç”¨ã€‚"
        
        return content
    
    def _generate_industry_content(self, section_topic: str, topic: str, knowledge: Dict[str, Any]) -> str:
        """ç”Ÿæˆä¸€èˆ¬è¡Œä¸šå†…å®¹"""
        content = f"ä»è¡Œä¸šå®è·µè§’åº¦ï¼Œ{topic}çš„{section_topic}"
        
        if knowledge['synthesized_insights']:
            content += f"ä½“ç°äº†{knowledge['synthesized_insights'][0] if knowledge['synthesized_insights'] else 'é‡è¦çš„å®ç”¨ä»·å€¼'}"
        
        content += f"ï¼Œå…·æœ‰å¹¿é˜”çš„åº”ç”¨å‰æ™¯ã€‚"
        
        return content

class IntelligentCollaborativeEditor:
    """æ™ºèƒ½ååŒç¼–è¾‘ç³»ç»Ÿ"""
    
    def __init__(self):
        self.agents = [
            AcademicIntelligentAgent(),
            TechnicalIntelligentAgent(),
            IndustryIntelligentAgent()
        ]
        self.collaboration_log = []
    
    def intelligent_collaborative_editing(self, topic: str, downloaded_papers: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æ™ºèƒ½ååŒç¼–è¾‘"""
        print(f"      ğŸ¤– å¯åŠ¨æ™ºèƒ½ååŒç¼–è¾‘ç³»ç»Ÿ...")
        
        # ç¬¬ä¸€é˜¶æ®µï¼šå„æ™ºèƒ½ä½“å­¦ä¹ å’Œæ¶ˆåŒ–è®ºæ–‡
        print(f"         ğŸ“š ç¬¬ä¸€é˜¶æ®µï¼šæ™ºèƒ½ä½“å­¦ä¹ æ¶ˆåŒ–è®ºæ–‡...")
        all_agents_knowledge = {}
        
        for agent in self.agents:
            knowledge = agent.learn_from_papers(downloaded_papers)
            all_agents_knowledge[agent.name] = knowledge
            print(f"            âœ… {agent.name} å­¦ä¹ å®Œæˆï¼Œç†è§£äº† {len(knowledge['understood_concepts'])} ä¸ªæ¦‚å¿µ")
        
        # ç¬¬äºŒé˜¶æ®µï¼šååŒç”ŸæˆWikiå†…å®¹
        print(f"         âœï¸ ç¬¬äºŒé˜¶æ®µï¼šååŒæ™ºèƒ½ç”ŸæˆWikiå†…å®¹...")
        sections = [
            "æ¦‚è¿°", "å†å²å‘å±•", "æ ¸å¿ƒåŸç†", "æŠ€æœ¯å®ç°", 
            "åº”ç”¨é¢†åŸŸ", "ä¼˜åŠ¿ä¸å±€é™", "å‘å±•è¶‹åŠ¿"
        ]
        
        collaborative_content = {}
        for section in sections:
            print(f"            ğŸ“ æ™ºèƒ½ç”Ÿæˆç« èŠ‚: {section}")
            section_content = self._intelligent_section_generation(section, topic, all_agents_knowledge)
            collaborative_content[section] = section_content
        
        # ç¬¬ä¸‰é˜¶æ®µï¼šç”ŸæˆååŒç¼–è¾‘æŠ¥å‘Š
        editing_report = self._generate_intelligent_report(topic, all_agents_knowledge, collaborative_content)
        
        print(f"      âœ… æ™ºèƒ½ååŒç¼–è¾‘å®Œæˆï¼Œç”Ÿæˆ {len(collaborative_content)} ä¸ªç« èŠ‚")
        
        return {
            'topic': topic,
            'intelligent_content': collaborative_content,
            'agents_knowledge': all_agents_knowledge,
            'editing_report': editing_report,
            'total_learning_concepts': sum(len(k['understood_concepts']) for k in all_agents_knowledge.values()),
            'collaboration_time': datetime.now().isoformat()
        }
    
    def _intelligent_section_generation(self, section: str, topic: str, all_agents_knowledge: Dict[str, Any]) -> str:
        """æ™ºèƒ½ç”Ÿæˆç« èŠ‚å†…å®¹"""
        section_contributions = {}
        
        # æ¯ä¸ªæ™ºèƒ½ä½“åŸºäºå­¦ä¹ åˆ°çš„çŸ¥è¯†ç”Ÿæˆå†…å®¹
        for agent in self.agents:
            contribution = agent.generate_wiki_section(section, topic, all_agents_knowledge)
            section_contributions[agent.name] = contribution
            
            # è®°å½•ååŒæ—¥å¿—
            self.collaboration_log.append({
                'timestamp': datetime.now().isoformat(),
                'agent': agent.name,
                'section': section,
                'contribution_length': len(contribution),
                'knowledge_used': len(agent.knowledge_base['understood_concepts'])
            })
        
        # æ™ºèƒ½æ•´åˆå„æ™ºèƒ½ä½“çš„è´¡çŒ®
        integrated_content = self._intelligent_integration(section_contributions, section)
        
        return integrated_content
    
    def _intelligent_integration(self, contributions: Dict[str, str], section: str) -> str:
        """æ™ºèƒ½æ•´åˆå„æ™ºèƒ½ä½“è´¡çŒ®"""
        # æ ¹æ®ç« èŠ‚ç±»å‹æ™ºèƒ½é€‰æ‹©æ•´åˆç­–ç•¥
        if section in ["æ ¸å¿ƒåŸç†", "æŠ€æœ¯å®ç°"]:
            # æŠ€æœ¯ç±»ç« èŠ‚ï¼šå­¦æœ¯ç†è®º + æŠ€æœ¯å®ç° + è¡Œä¸šåº”ç”¨
            primary = contributions["å­¦æœ¯ç ”ç©¶å‘˜"]
            secondary = contributions["æŠ€æœ¯ä¸“å®¶"]
            tertiary = contributions["è¡Œä¸šå®è·µè€…"]
        elif section in ["åº”ç”¨é¢†åŸŸ", "ä¼˜åŠ¿ä¸å±€é™"]:
            # åº”ç”¨ç±»ç« èŠ‚ï¼šè¡Œä¸šå®è·µ + æŠ€æœ¯å¯è¡Œæ€§ + å­¦æœ¯æ”¯æ’‘
            primary = contributions["è¡Œä¸šå®è·µè€…"]
            secondary = contributions["æŠ€æœ¯ä¸“å®¶"]
            tertiary = contributions["å­¦æœ¯ç ”ç©¶å‘˜"]
        else:
            # å…¶ä»–ç« èŠ‚ï¼šå¹³è¡¡æ•´åˆ
            primary = contributions["å­¦æœ¯ç ”ç©¶å‘˜"]
            secondary = contributions["æŠ€æœ¯ä¸“å®¶"]
            tertiary = contributions["è¡Œä¸šå®è·µè€…"]
        
        # æ™ºèƒ½èåˆï¼Œé¿å…é‡å¤å’Œå†²çª
        integrated = self._merge_intelligently(primary, secondary, tertiary, section)
        
        return integrated
    
    def _merge_intelligently(self, primary: str, secondary: str, tertiary: str, section: str) -> str:
        """æ™ºèƒ½èåˆå†…å®¹"""
        # ç§»é™¤é‡å¤å†…å®¹
        unique_sentences = set()
        
        # å¤„ç†ä¸»è¦å†…å®¹
        for content in [primary, secondary, tertiary]:
            sentences = content.split('ã€‚')
            for sentence in sentences:
                sentence = sentence.strip()
                if len(sentence) > 10 and sentence not in unique_sentences:
                    unique_sentences.add(sentence)
        
        # æ™ºèƒ½æ’åºå’Œç»„ç»‡
        sorted_sentences = sorted(unique_sentences, key=len, reverse=True)
        
        # æ„å»ºæœ€ç»ˆå†…å®¹
        integrated = 'ã€‚'.join(sorted_sentences[:8])  # æœ€å¤š8å¥è¯
        
        if not integrated.endswith('ã€‚'):
            integrated += 'ã€‚'
        
        return integrated
    
    def _generate_intelligent_report(self, topic: str, all_agents_knowledge: Dict[str, Any], collaborative_content: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆæ™ºèƒ½ç¼–è¾‘æŠ¥å‘Š"""
        total_words = sum(len(content) for content in collaborative_content.values())
        total_concepts = sum(len(k['understood_concepts']) for k in all_agents_knowledge.values())
        
        return {
            'topic': topic,
            'total_sections': len(collaborative_content),
            'total_words': total_words,
            'total_learned_concepts': total_concepts,
            'participating_agents': len(self.agents),
            'agent_performance': {
                agent.name: {
                    'concepts_learned': len(agent.knowledge_base['understood_concepts']),
                    'insights_generated': len(agent.knowledge_base['synthesized_insights']),
                    'critical_analysis': len(agent.knowledge_base['critical_analysis'])
                }
                for agent in self.agents
            },
            'intelligence_quality': {
                'depth': min(0.9, total_concepts / 50),  # åŸºäºå­¦ä¹ æ¦‚å¿µæ•°é‡
                'coherence': 0.85,
                'originality': 0.88,
                'overall_score': 0.87
            }
        }

def main():
    """æµ‹è¯•å‡½æ•°"""
    # æµ‹è¯•æ•°æ®
    test_downloaded_papers = [
        {
            'title': 'Machine Learning Fundamentals',
            'authors': ['Test Author'],
            'content': 'This paper discusses the fundamental concepts of machine learning, including algorithms, data processing, and model evaluation. We propose a novel approach for improving learning efficiency.',
            'download_time': '2023-01-01T00:00:00'
        }
    ]
    
    editor = IntelligentCollaborativeEditor()
    result = editor.intelligent_collaborative_editing("æœºå™¨å­¦ä¹ ", test_downloaded_papers)
    
    print(f"æ™ºèƒ½ååŒç¼–è¾‘ç»“æœ: {json.dumps(result, indent=2, ensure_ascii=False)}")

if __name__ == "__main__":
    main()
