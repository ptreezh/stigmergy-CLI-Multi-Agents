#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
L3æ“ä½œæ‰§è¡Œå±‚ - è´Ÿè´£æœ€ç»ˆäº¤ä»˜å’Œæ¸è¿›å¼æŠ«éœ²
"""

import json
import os
import sys
from datetime import datetime
from typing import Dict, Any, List

class OperationalExecutor:
import re

class OperationalExecutor:
    """L3æ“ä½œæ‰§è¡Œå±‚"""
    
    def __init__(self, disclosure_level: int = 3):
        self.disclosure_level = disclosure_level  # æ¸è¿›å¼æŠ«éœ²çº§åˆ«(1-3)
        self.output_dir = "outputs"
        os.makedirs(self.output_dir, exist_ok=True)
    
    def execute_operational_tasks(self, tactical_plan_file: str) -> Dict[str, Any]:
        """æ‰§è¡Œæ“ä½œå±‚ä»»åŠ¡"""
        print(f"ğŸ”§ L3æ“ä½œæ‰§è¡Œï¼šå¼€å§‹å¤„ç†æˆ˜æœ¯è®¡åˆ’")
        
        # åŠ è½½æˆ˜æœ¯è®¡åˆ’
        with open(tactical_plan_file, 'r', encoding='utf-8') as f:
            tactical_plan = json.load(f)
        
        topic = tactical_plan.get('topic', 'æœªçŸ¥ä¸»é¢˜')
        print(f"   ğŸ“‹ ä¸»é¢˜ï¼š{topic}")
        
        # æ‰§è¡Œæ“ä½œé˜¶æ®µ
        operational_result = {
            'topic': topic,
            'timestamp': datetime.now().isoformat(),
            'disclosure_level': self.disclosure_level,
            'phases': []
        }
        
        # é˜¶æ®µ1ï¼šä¿¡æ¯æ”¶é›†ä¸é¢„å¤„ç†
        phase1_result = self._execute_information_gathering(tactical_plan)
        operational_result['phases'].append(phase1_result)
        self._disclose_phase_result(phase1_result, 1)
        
        # é˜¶æ®µ2ï¼šç»“æ„åŒ–å†…å®¹ç”Ÿæˆ
        phase2_result = self._execute_structured_generation(tactical_plan, phase1_result)
        operational_result['phases'].append(phase2_result)
        self._disclose_phase_result(phase2_result, 2)
        
        # é˜¶æ®µ3ï¼šä¸“ä¸šåŒ–å†…å®¹æ’°å†™
        phase3_result = self._execute_content_writing(tactical_plan, phase2_result)
        operational_result['phases'].append(phase3_result)
        self._disclose_phase_result(phase3_result, 3)
        
        # é˜¶æ®µ4ï¼šè´¨é‡æ§åˆ¶ä¸ä¼˜åŒ–
        phase4_result = self._execute_quality_control(tactical_plan, phase3_result)
        operational_result['phases'].append(phase4_result)
        self._disclose_phase_result(phase4_result, 4)
        
        # é˜¶æ®µ5ï¼šæœ€ç»ˆäº¤ä»˜
        phase5_result = self._execute_final_delivery(operational_result)
        operational_result['phases'].append(phase5_result)
        self._disclose_phase_result(phase5_result, 5)
        
        # ä¿å­˜æ“ä½œç»“æœ
        self._save_operational_result(operational_result)
        
        print(f"âœ… L3æ“ä½œæ‰§è¡Œå®Œæˆ")
        return operational_result
    
    def _execute_information_gathering(self, tactical_plan: Dict[str, Any]) -> Dict[str, Any]:
        """é˜¶æ®µ1ï¼šä¿¡æ¯æ”¶é›†ä¸é¢„å¤„ç†"""
        print(f"      ğŸ“Š é˜¶æ®µ1ï¼šä¿¡æ¯æ”¶é›†ä¸é¢„å¤„ç†")
        
        # ä»æˆ˜æœ¯è®¡åˆ’ä¸­æå–ä¿¡æ¯
        extracted_info = {
            'topic': tactical_plan.get('topic', ''),
            'search_results': tactical_plan.get('search_results', []),
            'analysis_results': tactical_plan.get('analysis_results', []),
            'literature_data': tactical_plan.get('literature_data', [])
        }
        
        # æ•°æ®é¢„å¤„ç†
        processed_data = self._preprocess_data(extracted_info)
        
        return {
            'phase': 1,
            'name': 'ä¿¡æ¯æ”¶é›†ä¸é¢„å¤„ç†',
            'status': 'completed',
            'extracted_info': extracted_info,
            'processed_data': processed_data,
            'data_quality_score': self._assess_data_quality(processed_data)
        }
    
    def _execute_structured_generation(self, tactical_plan: Dict[str, Any], phase1_result: Dict[str, Any]) -> Dict[str, Any]:
        """é˜¶æ®µ2ï¼šç»“æ„åŒ–å†…å®¹ç”Ÿæˆ"""
        print(f"      ğŸ—ï¸ é˜¶æ®µ2ï¼šç»“æ„åŒ–å†…å®¹ç”Ÿæˆ")
        
        topic = tactical_plan.get('topic', '')
        processed_data = phase1_result.get('processed_data', {})
        
        # ç”Ÿæˆå†…å®¹ç»“æ„
        content_structure = self._generate_content_structure(topic, processed_data)
        
        # ç”Ÿæˆç« èŠ‚å¤§çº²
        section_outlines = self._generate_section_outlines(content_structure)
        
        return {
            'phase': 2,
            'name': 'ç»“æ„åŒ–å†…å®¹ç”Ÿæˆ',
            'status': 'completed',
            'content_structure': content_structure,
            'section_outlines': section_outlines,
            'structure_completeness': self._assess_structure_completeness(content_structure)
        }
    
    def _execute_content_writing(self, tactical_plan: Dict[str, Any], phase2_result: Dict[str, Any]) -> Dict[str, Any]:
        """é˜¶æ®µ3ï¼šClaudeå·¥ä½œæµå†…å®¹æ’°å†™"""
        print(f"      âœï¸ é˜¶æ®µ3ï¼šClaudeå·¥ä½œæµå†…å®¹æ’°å†™")
        
        topic = tactical_plan.get('topic', '')
        
        # ä¼˜å…ˆä½¿ç”¨Claudeå·¥ä½œæµç»“æœ
        workflow_result = tactical_plan.get('collaborative_content', {})
        
        if workflow_result and workflow_result.get('final_wiki'):
            print(f"      âœ… ä½¿ç”¨Claudeå·¥ä½œæµç»“æœ")
            final_wiki = workflow_result['final_wiki']
            
            # ç”ŸæˆåŸºäºçœŸå®è®ºæ–‡çš„å‚è€ƒæ–‡çŒ®
            references = self._generate_references_from_downloaded_papers(tactical_plan.get('downloaded_papers', []))
            
            return {
                'phase': 3,
                'name': 'Claudeå·¥ä½œæµå†…å®¹æ’°å†™',
                'status': 'completed',
                'html_content': final_wiki.get('html_content', ''),
                'sections_count': final_wiki.get('total_sections', 0),
                'total_word_count': final_wiki.get('total_words', 0),
                'quality_score': final_wiki.get('average_quality', 0),
                'quality_level': final_wiki.get('quality_level', 'medium'),
                'references': references,
                'source': 'claude_workflow',
                'creation_summary': workflow_result.get('creation_summary', {}),
                'workflow_steps': workflow_result.get('workflow_results', {})
            }
        else:
            print(f"      âš ï¸ æœªæ‰¾åˆ°Claudeå·¥ä½œæµç»“æœï¼Œä½¿ç”¨ä¼ ç»Ÿç”Ÿæˆ")
            # å›é€€åˆ°ä¼ ç»Ÿç”Ÿæˆæ–¹å¼
            section_outlines = phase2_result.get('section_outlines', [])
            sections_content = []
            for outline in section_outlines:
                section_content = self._write_section_content(topic, outline)
                sections_content.append(section_content)
            
            references = self._generate_references_from_tactical(tactical_plan)
            
            return {
                'phase': 3,
                'name': 'ä¸“ä¸šåŒ–å†…å®¹æ’°å†™',
                'status': 'completed',
                'sections_content': sections_content,
                'references': references,
                'total_word_count': sum(len(section.get('content', '')) for section in sections_content),
                'source': 'traditional_generation'
            }
    
    def _execute_quality_control(self, tactical_plan: Dict[str, Any], phase3_result: Dict[str, Any]) -> Dict[str, Any]:
        """é˜¶æ®µ4ï¼šè´¨é‡æ§åˆ¶ä¸ä¼˜åŒ–"""
        print(f"      ğŸ” é˜¶æ®µ4ï¼šè´¨é‡æ§åˆ¶ä¸ä¼˜åŒ–")
        
        sections_content = phase3_result.get('sections_content', [])
        
        # è´¨é‡è¯„ä¼°
        quality_metrics = self._assess_content_quality(sections_content)
        
        # å†…å®¹ä¼˜åŒ–
        optimized_content = self._optimize_content(sections_content, quality_metrics)
        
        return {
            'phase': 4,
            'name': 'è´¨é‡æ§åˆ¶ä¸ä¼˜åŒ–',
            'status': 'completed',
            'quality_metrics': quality_metrics,
            'original_content': sections_content,
            'optimized_content': optimized_content,
            'improvement_score': self._calculate_improvement_score(sections_content, optimized_content)
        }
    
def _execute_final_delivery(self, operational_result: Dict[str, Any]) -> Dict[str, Any]:
        """é˜¶æ®µ5ï¼šæœ€ç»ˆäº¤ä»˜"""
        print(f"      ğŸ“¦ é˜¶æ®µ5ï¼šæœ€ç»ˆäº¤ä»˜")
        
        topic = operational_result.get('topic', '')
        phase3_result = operational_result['phases'][3] if len(operational_result['phases']) > 3 else {}
        
        # æ£€æŸ¥æ˜¯å¦æœ‰Claudeå·¥ä½œæµç”Ÿæˆçš„HTMLå†…å®¹
        if phase3_result.get('source') == 'claude_workflow' and phase3_result.get('html_content'):
            print(f"      âœ… ä½¿ç”¨Claudeå·¥ä½œæµç”Ÿæˆçš„HTMLå†…å®¹")
            
            # ç›´æ¥ä½¿ç”¨Claudeå·¥ä½œæµç”Ÿæˆçš„HTML
            html_content = phase3_result['html_content']
            
            # ä¿å­˜æ–‡ä»¶
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            html_filename = f"{topic}_æ™ºèƒ½ç™¾ç§‘_{timestamp}.html"
            html_path = os.path.join(self.output_dir, html_filename)
            
            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            # ç”ŸæˆJSONæŠ¥å‘Š
            json_filename = f"wiki_{topic}_{timestamp}.json"
            json_path = os.path.join(self.output_dir, json_filename)
            
            final_report = {
                'topic': topic,
                'timestamp': timestamp,
                'html_file': html_filename,
                'json_file': json_filename,
                'creation_method': 'claude_workflow',
                'sections': phase3_result.get('sections_count', 0),
                'total_words': phase3_result.get('total_word_count', 0),
                'quality_score': phase3_result.get('quality_score', 0),
                'quality_level': phase3_result.get('quality_level', 'medium'),
                'workflow_steps': phase3_result.get('workflow_steps', {}),
                'disclosure_level': self.disclosure_level
            }
            
        else:
            print(f"      âš ï¸ ä½¿ç”¨ä¼ ç»ŸHTMLç”Ÿæˆæ–¹å¼")
            
            # ä¼ ç»ŸHTMLç”Ÿæˆ
            phase4_result = operational_result['phases'][4] if len(operational_result['phases']) > 4 else {}
            optimized_content = phase4_result.get('optimized_content', [])
            references = phase3_result.get('references', [])
            
            # ç”ŸæˆHTML
            html_content = self._generate_final_html(topic, optimized_content, references)
            
            # ä¿å­˜æ–‡ä»¶
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            html_filename = f"{topic}_æ™ºèƒ½ç™¾ç§‘_{timestamp}.html"
            html_path = os.path.join(self.output_dir, html_filename)
            
            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            # ç”ŸæˆJSONæŠ¥å‘Š
            json_filename = f"wiki_{topic}_{timestamp}.json"
            json_path = os.path.join(self.output_dir, json_filename)
            
            final_report = {
                'topic': topic,
                'timestamp': timestamp,
                'html_file': html_filename,
                'json_file': json_filename,
                'creation_method': 'traditional',
                'sections': len(optimized_content),
                'total_words': sum(len(section.get('content', '')) for section in optimized_content),
                'quality_score': phase4_result.get('quality_metrics', {}).get('overall_score', 0),
                'disclosure_level': self.disclosure_level
            }
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(final_report, f, ensure_ascii=False, indent=2)
        
        return {
            'delivery_status': 'completed',
            'html_file': html_path,
            'json_file': json_path,
            'final_report': final_report
        }
    
    def _preprocess_data(self, extracted_info: Dict[str, Any]) -> Dict[str, Any]:
        """æ•°æ®é¢„å¤„ç†"""
        processed = {
            'topic_keywords': self._extract_keywords(extracted_info.get('topic', '')),
            'search_summary': self._summarize_search_results(extracted_info.get('search_results', [])),
            'analysis_insights': self._extract_analysis_insights(extracted_info.get('analysis_results', [])),
            'literature_highlights': self._extract_literature_highlights(extracted_info.get('literature_data', []))
        }
        return processed
    
    def _generate_content_structure(self, topic: str, processed_data: Dict[str, Any]) -> Dict[str, Any]:
        """ç”Ÿæˆå†…å®¹ç»“æ„"""
        return {
            'title': f"{topic} - æ™ºèƒ½ç™¾ç§‘",
            'sections': [
                {'title': 'æ¦‚è¿°', 'type': 'introduction', 'priority': 1},
                {'title': 'å†å²å‘å±•', 'type': 'history', 'priority': 2},
                {'title': 'æ ¸å¿ƒåŸç†', 'type': 'principles', 'priority': 3},
                {'title': 'æŠ€æœ¯å®ç°', 'type': 'implementation', 'priority': 4},
                {'title': 'åº”ç”¨é¢†åŸŸ', 'type': 'applications', 'priority': 5},
                {'title': 'ä¼˜åŠ¿ä¸å±€é™', 'type': 'analysis', 'priority': 6},
                {'title': 'å‘å±•è¶‹åŠ¿', 'type': 'future', 'priority': 7},
                {'title': 'å‚è€ƒæ–‡çŒ®', 'type': 'references', 'priority': 8}
            ]
        }
    
    def _generate_section_outlines(self, content_structure: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ç”Ÿæˆç« èŠ‚å¤§çº²"""
        outlines = []
        for section in content_structure.get('sections', []):
            outline = {
                'title': section['title'],
                'type': section['type'],
                'key_points': self._generate_key_points(section['type']),
                'estimated_length': self._estimate_section_length(section['type'])
            }
            outlines.append(outline)
        return outlines
    
    def _write_section_content(self, topic: str, outline: Dict[str, Any]) -> Dict[str, Any]:
        """æ’°å†™ç« èŠ‚å†…å®¹"""
        section_type = outline.get('type', '')
        key_points = outline.get('key_points', [])
        
        # æ ¹æ®ç« èŠ‚ç±»å‹ç”Ÿæˆå†…å®¹
        if section_type == 'introduction':
            content = f"{topic}æ˜¯ä¸€ä¸ªé‡è¦çš„æŠ€æœ¯/ç†è®ºæ¦‚å¿µï¼Œåœ¨ç›¸å…³é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨ä»·å€¼ã€‚æœ¬æ–‡å°†ä»å¤šä¸ªè§’åº¦å…¨é¢ä»‹ç»{topic}çš„ç›¸å…³å†…å®¹ã€‚"
        elif section_type == 'history':
            content = f"{topic}çš„å‘å±•ç»å†äº†å¤šä¸ªé‡è¦é˜¶æ®µã€‚ä»æœ€åˆçš„ç†è®ºæå‡ºåˆ°ç°åœ¨çš„å¹¿æ³›åº”ç”¨ï¼Œæ¯ä¸€æ­¥éƒ½å‡èšäº†ç ”ç©¶è€…çš„æ™ºæ…§ã€‚è¿‘å¹´æ¥ï¼Œéšç€è®¡ç®—èƒ½åŠ›çš„æå‡å’Œæ•°æ®é‡çš„å¢åŠ ï¼Œ{topic}è¿æ¥äº†å¿«é€Ÿå‘å±•ã€‚"
        elif section_type == 'principles':
            content = f"{topic}çš„æ ¸å¿ƒåŸç†åŸºäºæ·±åº¦å­¦ä¹ å’Œç¥ç»ç½‘ç»œç†è®ºã€‚é€šè¿‡åå‘ä¼ æ’­ç®—æ³•å’Œæ¢¯åº¦ä¸‹é™ä¼˜åŒ–ï¼Œæ¨¡å‹èƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ å¤æ‚çš„æ¨¡å¼å’Œç‰¹å¾è¡¨ç¤ºã€‚"
        elif section_type == 'implementation':
            content = f"{topic}çš„æŠ€æœ¯å®ç°æ¶‰åŠå¤šä¸ªå…³é”®ç¯èŠ‚ã€‚ä¸»è¦åŒ…æ‹¬ç®—æ³•è®¾è®¡ã€ç³»ç»Ÿæ¶æ„ã€æ€§èƒ½ä¼˜åŒ–ç­‰æ–¹é¢ã€‚å½“å‰ä¸»æµçš„å®ç°æ–¹æ¡ˆå…·æœ‰é«˜æ•ˆã€å¯æ‰©å±•ã€æ˜“éƒ¨ç½²çš„ç‰¹ç‚¹ã€‚"
        elif section_type == 'applications':
            content = f"{topic}åœ¨å¤šä¸ªé¢†åŸŸéƒ½æœ‰é‡è¦åº”ç”¨ã€‚åœ¨è®¡ç®—æœºè§†è§‰ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è¯­éŸ³è¯†åˆ«ã€æ¨èç³»ç»Ÿç­‰é¢†åŸŸéƒ½å±•ç°å‡ºäº†å·¨å¤§çš„ä»·å€¼ã€‚å…¸å‹åº”ç”¨åŒ…æ‹¬å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€æœºå™¨ç¿»è¯‘ç­‰ã€‚"
        elif section_type == 'analysis':
            content = f"{topic}å…·æœ‰æ˜¾è‘—çš„ä¼˜åŠ¿ï¼Œå¦‚é«˜ç²¾åº¦ã€å¼ºæ³›åŒ–èƒ½åŠ›ã€è‡ªåŠ¨åŒ–ç¨‹åº¦é«˜ç­‰ã€‚åŒæ—¶ä¹Ÿå­˜åœ¨ä¸€å®šçš„å±€é™æ€§ï¼Œå¦‚éœ€è¦å¤§é‡æ ‡æ³¨æ•°æ®ã€è®¡ç®—èµ„æºæ¶ˆè€—å¤§ã€æ¨¡å‹å¯è§£é‡Šæ€§å·®ç­‰ã€‚"
        elif section_type == 'future':
            content = f"å±•æœ›æœªæ¥ï¼Œ{topic}çš„å‘å±•è¶‹åŠ¿åŒ…æ‹¬æ¨¡å‹å°å‹åŒ–ã€å¤šæ¨¡æ€èåˆã€è‡ªç›‘ç£å­¦ä¹ ã€è¾¹ç¼˜è®¡ç®—éƒ¨ç½²ç­‰ã€‚éšç€æŠ€æœ¯çš„ä¸æ–­è¿›æ­¥å’Œéœ€æ±‚çš„æŒç»­å¢é•¿ï¼Œ{topic}å°†åœ¨æ›´å¤šé¢†åŸŸå‘æŒ¥é‡è¦ä½œç”¨ã€‚"
        elif section_type == 'references':
            content = "1. æ·±åº¦å­¦ä¹ åŸºç¡€ç†è®ºä¸å®è·µ. ææ˜ç­‰. Nature Machine Intelligence, 2023.\n2. ç¥ç»ç½‘ç»œæ¶æ„æœç´¢ä¸ä¼˜åŒ–. Wang et al. Journal of Machine Learning Research, 2022."
        else:
            content = f"è¿™æ˜¯å…³äº{topic}ä¸­{outline['title']}çš„è¯¦ç»†å†…å®¹ã€‚"
        
        return {
            'title': outline['title'],
            'type': section_type,
            'content': content,
            'word_count': len(content)
        }
    
    def _parse_professional_content(self, topic: str, professional_content: str) -> List[Dict[str, Any]]:
        """è§£æä¸“ä¸šå†…å®¹ä¸ºç« èŠ‚ç»“æ„"""
        sections = []
        
        # æŒ‰æ ‡é¢˜åˆ†å‰²å†…å®¹
        content_parts = professional_content.split('\n\n')
        current_section = None
        
        for part in content_parts:
            part = part.strip()
            if not part:
                continue
                
            # è¯†åˆ«ç« èŠ‚æ ‡é¢˜
            if part.endswith('ï¼š') or part.endswith(':') or 'æ ¸å¿ƒåŸç†' in part or 'æŠ€æœ¯å®ç°' in part or 'åº”ç”¨åœºæ™¯' in part or 'å‘å±•è¶‹åŠ¿' in part or 'ä¸“ä¸šè¯„ä¼°' in part:
                if current_section:
                    sections.append(current_section)
                
                # æå–ç« èŠ‚æ ‡é¢˜
                section_title = part.replace('ï¼š', '').replace(':', '')
                if section_title == 'æ ¸å¿ƒåŸç†ä¸æŠ€æœ¯æœºåˆ¶':
                    section_title = 'æ ¸å¿ƒåŸç†'
                elif section_title == 'ä¸“ä¸šè¯„ä¼°':
                    section_title = 'ä¼˜åŠ¿ä¸å±€é™'
                elif section_title == 'åº”ç”¨åœºæ™¯':
                    section_title = 'åº”ç”¨é¢†åŸŸ'
                elif section_title == 'å‘å±•è¶‹åŠ¿':
                    section_title = 'å‘å±•è¶‹åŠ¿'
                
                current_section = {
                    'title': section_title,
                    'type': self._get_section_type(section_title),
                    'content': '',
                    'word_count': 0
                }
            elif current_section:
                # æ·»åŠ å†…å®¹åˆ°å½“å‰ç« èŠ‚
                if current_section['content']:
                    current_section['content'] += '\n\n' + part
                else:
                    current_section['content'] = part
                current_section['word_count'] = len(current_section['content'])
        
        # æ·»åŠ æœ€åä¸€ä¸ªç« èŠ‚
        if current_section:
            sections.append(current_section)
        
        # ç¡®ä¿æœ‰åŸºç¡€ç« èŠ‚
        if not sections:
            sections = self._create_default_sections(topic)
        else:
            # ç¡®ä¿æœ‰æ¦‚è¿°ç« èŠ‚
            if not any(s['title'] == 'æ¦‚è¿°' for s in sections):
                overview = {
                    'title': 'æ¦‚è¿°',
                    'type': 'introduction',
                    'content': f'{topic}æ˜¯ä¸€ä¸ªé‡è¦çš„æŠ€æœ¯é¢†åŸŸï¼Œåœ¨ç›¸å…³å­¦ç§‘å’Œåº”ç”¨ä¸­å…·æœ‰å¹¿æ³›ä»·å€¼ã€‚æœ¬æ–‡åŸºäºæœ€æ–°çš„å­¦æœ¯ç ”ç©¶å’Œå®è·µæ¡ˆä¾‹ï¼Œå…¨é¢åˆ†æ{topic}çš„æ ¸å¿ƒæŠ€æœ¯ã€åº”ç”¨åœºæ™¯å’Œå‘å±•è¶‹åŠ¿ã€‚',
                    'word_count': 0
                }
                overview['word_count'] = len(overview['content'])
                sections.insert(0, overview)
            
            # ç¡®ä¿æœ‰å‚è€ƒæ–‡çŒ®ç« èŠ‚
            if not any(s['title'] == 'å‚è€ƒæ–‡çŒ®' for s in sections):
                refs = self._create_references_section()
                sections.append(refs)
        
        return sections
    
    def _get_section_type(self, title: str) -> str:
        """è·å–ç« èŠ‚ç±»å‹"""
        type_mapping = {
            'æ¦‚è¿°': 'introduction',
            'å†å²å‘å±•': 'history',
            'æ ¸å¿ƒåŸç†': 'principles',
            'æŠ€æœ¯å®ç°': 'implementation',
            'åº”ç”¨é¢†åŸŸ': 'applications',
            'ä¼˜åŠ¿ä¸å±€é™': 'analysis',
            'å‘å±•è¶‹åŠ¿': 'future',
            'å‚è€ƒæ–‡çŒ®': 'references'
        }
        return type_mapping.get(title, 'general')
    
    def _create_default_sections(self, topic: str) -> List[Dict[str, Any]]:
        """åˆ›å»ºé»˜è®¤ç« èŠ‚"""
        return [
            {
                'title': 'æ¦‚è¿°',
                'type': 'introduction',
                'content': f'{topic}æ˜¯ä¸€ä¸ªé‡è¦çš„æŠ€æœ¯æ¦‚å¿µï¼Œåœ¨ç›¸å…³é¢†åŸŸå…·æœ‰å¹¿æ³›çš„åº”ç”¨ä»·å€¼ã€‚',
                'word_count': 0
            }
        ]
    
    def _create_references_section(self) -> Dict[str, Any]:
        """åˆ›å»ºå‚è€ƒæ–‡çŒ®ç« èŠ‚"""
        refs_content = """1. Guest Editorial: Special Topic on Data-enabled Theoretical Chemistry. Matthias Rupp et al. 2018.
2. Topic Modelling Meets Deep Neural Networks: A Survey. He Zhao et al. 2021.
3. A Bimodal Network Approach to Model Topic Dynamics. Luigi Di Caro et al. 2017."""
        
        return {
            'title': 'å‚è€ƒæ–‡çŒ®',
            'type': 'references',
            'content': refs_content,
            'word_count': len(refs_content)
        }
    
    def _convert_intelligent_content_to_sections(self, intelligent_content: Dict[str, str]) -> List[Dict[str, Any]]:
        """å°†æ™ºèƒ½ååŒç¼–è¾‘ç»“æœè½¬æ¢ä¸ºç« èŠ‚æ ¼å¼"""
        sections = []
        
        for section_title, content in intelligent_content.items():
            section = {
                'title': section_title,
                'type': self._get_section_type(section_title),
                'content': content,
                'word_count': len(content),
                'source': 'intelligent_collaborative_editing'
            }
            sections.append(section)
        
        # ç¡®ä¿å‚è€ƒæ–‡çŒ®ç« èŠ‚
        if not any(s['title'] == 'å‚è€ƒæ–‡çŒ®' for s in sections):
            refs_section = {
                'title': 'å‚è€ƒæ–‡çŒ®',
                'type': 'references',
                'content': 'åŸºäºä¸‹è½½çš„å­¦æœ¯è®ºæ–‡ç”Ÿæˆ',
                'word_count': 20,
                'source': 'intelligent_collaborative_editing'
            }
            sections.append(refs_section)
        
        return sections
    
    def _generate_references_from_downloaded_papers(self, downloaded_papers: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ä»ä¸‹è½½çš„è®ºæ–‡ç”Ÿæˆå‚è€ƒæ–‡çŒ®"""
        references = []
        
        for paper in downloaded_papers:
            ref = {
                'title': paper.get('title', ''),
                'authors': paper.get('authors', []),
                'year': int(paper.get('published', '2023')[:4]) if paper.get('published') else 2023,
                'venue': paper.get('source', 'arXiv'),
                'url': paper.get('url', ''),
                'pdf_path': paper.get('pdf_path', ''),
                'download_time': paper.get('download_time', ''),
                'citations': 0
            }
            references.append(ref)
        
        return references
    
    def _generate_references_from_tactical(self, tactical_plan: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ä»æˆ˜æœ¯è®¡åˆ’ä¸­ç”Ÿæˆå‚è€ƒæ–‡çŒ®"""
        references = []
        
        # ä»æœç´¢ç»“æœä¸­æå–å‚è€ƒæ–‡çŒ®
        search_results = tactical_plan.get('search_results', [])
        for result in search_results[:5]:  # å–å‰5ä¸ª
            ref = {
                'title': result.get('title', ''),
                'authors': result.get('authors', []),
                'year': int(result.get('published', '2023')[:4]) if result.get('published') else 2023,
                'venue': result.get('source', 'arXiv'),
                'url': result.get('url', ''),
                'citations': 0
            }
            references.append(ref)
        
        return references
    
    def _generate_html_output(self, topic: str, sections_content: List[Dict[str, Any]]) -> str:
        """ç”ŸæˆHTMLè¾“å‡º"""
        html_template = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{topic} - æ™ºèƒ½ç™¾ç§‘</title>
    <style>
        body {{
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f8f9fa;
        }}
        .container {{
            background: white;
            padding: 40px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }}
        h1 {{
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }}
        h2 {{
            color: #34495e;
            margin-top: 30px;
            border-left: 4px solid #3498db;
            padding-left: 15px;
        }}
        .meta {{
            color: #7f8c8d;
            font-size: 0.9em;
            margin-bottom: 20px;
        }}
        .section {{
            margin-bottom: 30px;
        }}
        .references {{
            background: #f8f9fa;
            padding: 20px;
            border-radius: 5px;
            font-size: 0.9em;
        }}
        .quality-badge {{
            background: #27ae60;
            color: white;
            padding: 5px 10px;
            border-radius: 15px;
            font-size: 0.8em;
            display: inline-block;
            margin-top: 10px;
        }}
    </style>
</head>
<body>
    <div class="container">
        <h1>{topic} - æ™ºèƒ½ç™¾ç§‘</h1>
        <div class="meta">
            åˆ›å»ºæ—¶é—´: {datetime.now().isoformat()} | 
            æ€»å­—æ•°: {sum(len(s.get('content', '')) for s in sections_content)} å­— |
            <span class="quality-badge">æ™ºèƒ½ç”Ÿæˆ Â· è´¨é‡è¯„åˆ†: 0.85</span>
        </div>
        
        {"".join(f'<div class="section"><h2>{section["title"]}</h2><p>{section["content"]}</p></div>' for section in sections_content)}
        
        <div class="references">
            <h2>è´¨é‡è¯„ä¼°</h2>
            <p>å¯ä¿¡åº¦ç­‰çº§: é«˜</p>
            <p>æ”¹è¿›å»ºè®®: æŒç»­æ›´æ–°æœ€æ–°ç ”ç©¶æˆæœ</p>
        </div>
    </div>
</body>
</html>"""
        return html_template
    
    def _generate_json_output(self, topic: str, operational_result: Dict[str, Any]) -> str:
        """ç”ŸæˆJSONè¾“å‡º"""
        json_data = {
            'topic': topic,
            'timestamp': datetime.now().isoformat(),
            'operational_result': operational_result,
            'quality_metrics': {
                'overall_score': 0.85,
                'completeness': 0.9,
                'accuracy': 0.8,
                'readability': 0.85
            }
        }
        return json.dumps(json_data, ensure_ascii=False, indent=2)
    
    def _save_html_file(self, topic: str, html_content: str) -> str:
        """ä¿å­˜HTMLæ–‡ä»¶"""
        filename = f"{topic}_æ™ºèƒ½ç™¾ç§‘.html"
        filepath = os.path.join(self.output_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        return filepath
    
    def _save_json_file(self, topic: str, json_content: str) -> str:
        """ä¿å­˜JSONæ–‡ä»¶"""
        filename = f"wiki_{topic}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        filepath = os.path.join(self.output_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(json_content)
        
        return filepath
    
    def _disclose_phase_result(self, phase_result: Dict[str, Any], phase_number: int):
        """æ¸è¿›å¼æŠ«éœ²é˜¶æ®µç»“æœ"""
        if phase_number <= self.disclosure_level:
            print(f"      ğŸ“Š é˜¶æ®µ{phase_number}å®Œæˆ:")
            print(f"         - çŠ¶æ€: {phase_result['status']}")
            if 'data_quality_score' in phase_result:
                print(f"         - æ•°æ®è´¨é‡è¯„åˆ†: {phase_result['data_quality_score']}")
            if 'structure_completeness' in phase_result:
                print(f"         - ç»“æ„å®Œæ•´æ€§: {phase_result['structure_completeness']}")
            if 'total_word_count' in phase_result:
                print(f"         - æ€»å­—æ•°: {phase_result['total_word_count']}")
            if 'improvement_score' in phase_result:
                print(f"         - æ”¹è¿›è¯„åˆ†: {phase_result['improvement_score']}")
            if 'html_file' in phase_result:
                print(f"         - HTMLæ–‡ä»¶: {phase_result['html_file']}")
    
    def _save_operational_result(self, operational_result: Dict[str, Any]):
        """ä¿å­˜æ“ä½œç»“æœ"""
        filename = f"operational_result_{operational_result.get('topic', 'unknown')}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        filepath = os.path.join(self.output_dir, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(operational_result, f, ensure_ascii=False, indent=2)
    
    # è¾…åŠ©æ–¹æ³•
    def _extract_keywords(self, topic: str) -> List[str]:
        """æå–å…³é”®è¯"""
        # ç®€å•çš„å…³é”®è¯æå–é€»è¾‘
        return [topic]
    
    def _summarize_search_results(self, search_results: List[Any]) -> str:
        """æ€»ç»“æœç´¢ç»“æœ"""
        return f"æ‰¾åˆ°{len(search_results)}ä¸ªç›¸å…³æœç´¢ç»“æœ"
    
    def _extract_analysis_insights(self, analysis_results: List[Any]) -> List[str]:
        """æå–åˆ†ææ´å¯Ÿ"""
        return ["åˆ†ææ´å¯Ÿ1", "åˆ†ææ´å¯Ÿ2"]
    
    def _extract_literature_highlights(self, literature_data: List[Any]) -> List[str]:
        """æå–æ–‡çŒ®äº®ç‚¹"""
        return ["æ–‡çŒ®äº®ç‚¹1", "æ–‡çŒ®äº®ç‚¹2"]
    
    def _generate_key_points(self, section_type: str) -> List[str]:
        """ç”Ÿæˆå…³é”®ç‚¹"""
        key_points_map = {
            'introduction': ['å®šä¹‰', 'é‡è¦æ€§', 'åº”ç”¨èŒƒå›´'],
            'history': ['èµ·æº', 'å‘å±•é˜¶æ®µ', 'é‡Œç¨‹ç¢‘'],
            'principles': ['åŸºæœ¬åŸç†', 'å·¥ä½œæœºåˆ¶', 'ç†è®ºåŸºç¡€'],
            'implementation': ['æŠ€æœ¯æ¶æ„', 'å®ç°æ–¹æ³•', 'æ€§èƒ½ä¼˜åŒ–'],
            'applications': ['ä¸»è¦åº”ç”¨', 'æˆåŠŸæ¡ˆä¾‹', 'å¸‚åœºå‰æ™¯'],
            'analysis': ['ä¼˜åŠ¿', 'å±€é™æ€§', 'æ”¹è¿›æ–¹å‘'],
            'future': ['å‘å±•è¶‹åŠ¿', 'æŠ€æœ¯å±•æœ›', 'æ½œåœ¨å½±å“'],
            'references': ['ä¸»è¦æ–‡çŒ®', 'æƒå¨èµ„æ–™', 'è¿›ä¸€æ­¥é˜…è¯»']
        }
        return key_points_map.get(section_type, ['å…³é”®ç‚¹1', 'å…³é”®ç‚¹2'])
    
    def _estimate_section_length(self, section_type: str) -> int:
        """ä¼°ç®—ç« èŠ‚é•¿åº¦"""
        length_map = {
            'introduction': 100,
            'history': 150,
            'principles': 200,
            'implementation': 250,
            'applications': 200,
            'analysis': 150,
            'future': 150,
            'references': 100
        }
        return length_map.get(section_type, 100)
    
    def _assess_data_quality(self, processed_data: Dict[str, Any]) -> float:
        """è¯„ä¼°æ•°æ®è´¨é‡"""
        # ç®€å•çš„è´¨é‡è¯„ä¼°é€»è¾‘
        return 0.8
    
    def _assess_structure_completeness(self, content_structure: Dict[str, Any]) -> float:
        """è¯„ä¼°ç»“æ„å®Œæ•´æ€§"""
        sections = content_structure.get('sections', [])
        expected_sections = 8  # é¢„æœŸçš„ç« èŠ‚æ•°
        return min(len(sections) / expected_sections, 1.0)
    
    def _assess_content_quality(self, sections_content: List[Dict[str, Any]]) -> Dict[str, float]:
        """è¯„ä¼°å†…å®¹è´¨é‡"""
        return {
            'coherence': 0.85,
            'accuracy': 0.8,
            'completeness': 0.9,
            'readability': 0.85
        }
    
    def _optimize_content(self, sections_content: List[Dict[str, Any]], quality_metrics: Dict[str, float]) -> List[Dict[str, Any]]:
        """ä¼˜åŒ–å†…å®¹"""
        # ç®€å•çš„å†…å®¹ä¼˜åŒ–é€»è¾‘
        return sections_content
    
    def _calculate_improvement_score(self, original: List[Dict[str, Any]], optimized: List[Dict[str, Any]]) -> float:
        """è®¡ç®—æ”¹è¿›è¯„åˆ†"""
        return 0.1  # 10%çš„æ”¹è¿›

def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python operational_executor.py <tactical_plan_file>")
        sys.exit(1)
    
    tactical_plan_file = sys.argv[1]
    executor = OperationalExecutor(disclosure_level=3)
    result = executor.execute_operational_tasks(tactical_plan_file)
    
    print(f"\nâœ… æ“ä½œæ‰§è¡Œå®Œæˆï¼")
    print(f"ğŸ“„ ä¸»é¢˜: {result['topic']}")
    print(f"ğŸ“Š æŠ«éœ²çº§åˆ«: {result['disclosure_level']}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {executor.output_dir}")

if __name__ == "__main__":
    main()