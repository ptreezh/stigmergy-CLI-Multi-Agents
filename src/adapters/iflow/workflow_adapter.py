"""
iFlow CLI Workflow Pipelineé€‚é…å™¨

é€šè¿‡iFlow CLIçš„Workflow Pipelineç³»ç»Ÿå®ç°è·¨CLIè°ƒç”¨åŠŸèƒ½ã€‚
åŸºäºé€šç”¨workflowæ’ä»¶æ¶æ„ï¼Œæ”¯æŒçµæ´»çš„å·¥ä½œæµæ‰©å±•ã€‚
"""

import asyncio
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List, Union

from src.core.base_adapter import BaseCrossCLIAdapter
from src.core.parser import NaturalLanguageParser

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)


class WorkflowContext:
    """iFlow CLIå·¥ä½œæµä¸Šä¸‹æ–‡"""

    def __init__(self, workflow_id: str = "", stage: str = "", data: Dict = None):
        self.workflow_id = workflow_id
        self.stage = stage
        self.data = data or {}
        self.metadata = {
            'user_id': 'default_user',
            'session_id': '',
            'pipeline_config': {}
        }
        self.pipeline_name = "cross-cli-integration"
        self.version = "1.0.0"
        self.start_time = datetime.now()
        self.status = "pending"


class WorkflowStage:
    """å·¥ä½œæµé˜¶æ®µ"""

    def __init__(self, name: str, description: str = "", required: bool = True, timeout: int = 30):
        self.name = name
        self.description = description
        self.required = required
        self.timeout = timeout
        self.status = "pending"
        self.result = None
        self.error = None
        self.start_time = None
        self.end_time = None


class IFlowWorkflowAdapter(BaseCrossCLIAdapter):
    """
    iFlow CLI Workflow Pipelineé€‚é…å™¨

    é€šè¿‡iFlow CLIçš„Workflow Pipelineç³»ç»Ÿå®ç°è·¨CLIè°ƒç”¨åŠŸèƒ½ã€‚
    åŸºäºå·¥ä½œæµçš„æ— æŸæ‰©å±•å®ç°ã€‚

    Pipelineæœºåˆ¶:
    - on_workflow_start: å·¥ä½œæµå¼€å§‹æ—¶è§¦å‘
    - on_stage_complete: é˜¶æ®µå®Œæˆæ—¶è§¦å‘
    - on_workflow_success: å·¥ä½œæµæˆåŠŸå®Œæˆæ—¶è§¦å‘
    - on_workflow_error: å·¥ä½œæµé”™è¯¯æ—¶è§¦å‘
    - on_pipeline_ready: æµæ°´çº¿å°±ç»ªæ—¶è§¦å‘
    """

    def __init__(self, cli_name: str = "iflow"):
        super().__init__(cli_name)

        # Pipelineç›¸å…³å±æ€§
        self.pipeline_stages: List[WorkflowStage] = []
        self.workflow_hooks: Dict[str, callable] = {}
        self.processed_workflows: List[Dict] = []
        self.workflow_executions: List[Dict] = []
        self.task_queue: Optional[asyncio.Queue] = None

        # ç»Ÿè®¡ä¿¡æ¯
        self.stages_processed = 0
        self.cross_cli_calls_count = 0
        self.workflow_count = 0

        # é…ç½®
        self.pipeline_config: Dict = {}
        self.workflow_config: Dict = {}

        # ç»„ä»¶
        self.parser = NaturalLanguageParser()

        logger.info("iFlow Workflow Pipelineé€‚é…å™¨åˆå§‹åŒ–å®Œæˆ")

    async def initialize(self) -> bool:
        """
        åˆå§‹åŒ–é€‚é…å™¨

        Returns:
            bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
        """
        try:
            logger.info("å¼€å§‹åˆå§‹åŒ–iFlow Workflow Pipelineé€‚é…å™¨...")

            # 1. åŠ è½½Pipelineé…ç½®
            if not await self._load_pipeline_config():
                logger.error("Pipelineé…ç½®åŠ è½½å¤±è´¥")
                return False

            # 2. åˆå§‹åŒ–å·¥ä½œæµé˜¶æ®µ
            if not await self._initialize_workflow_stages():
                logger.error("å·¥ä½œæµé˜¶æ®µåˆå§‹åŒ–å¤±è´¥")
                return False

            # 3. æ³¨å†Œå·¥ä½œæµHooks
            if not await self._register_workflow_hooks():
                logger.error("å·¥ä½œæµHooksæ³¨å†Œå¤±è´¥")
                return False

            # 4. åˆå§‹åŒ–ä»»åŠ¡é˜Ÿåˆ—
            if not await self._initialize_task_queue():
                logger.error("ä»»åŠ¡é˜Ÿåˆ—åˆå§‹åŒ–å¤±è´¥")
                return False

            # 5. åˆ›å»ºå·¥ä½œæµé…ç½®ç›®å½•
            await self._ensure_config_directory()

            logger.info("iFlow Workflow Pipelineé€‚é…å™¨åˆå§‹åŒ–æˆåŠŸ")
            return True

        except Exception as e:
            logger.error(f"åˆå§‹åŒ–iFlow Workflow Pipelineé€‚é…å™¨å¤±è´¥: {e}")
            return False

    async def _load_pipeline_config(self) -> bool:
        """
        åŠ è½½Pipelineé…ç½®

        Returns:
            bool: åŠ è½½æ˜¯å¦æˆåŠŸ
        """
        try:
            config_path = Path(__file__).parent / "config.json"

            if config_path.exists():
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)

                self.pipeline_config = config
                self.workflow_config = config.get('workflow', {})
                logger.info("Pipelineé…ç½®åŠ è½½æˆåŠŸ")
                return True
            else:
                logger.warning("Pipelineé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                self.pipeline_config = self._get_default_config()
                return True

        except Exception as e:
            logger.error(f"åŠ è½½Pipelineé…ç½®å¤±è´¥: {e}")
            return False

    def _get_default_config(self) -> Dict:
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "adapter_name": "iFlow Workflow Pipeline Adapter",
            "pipeline_mechanism": "workflow_pipeline",
            "supported_clis": ["claude", "gemini", "qwencode", "qoder", "codebuddy", "codex"],
            "workflow": {
                "default_settings": {
                    "parallel_execution": True,
                    "error_handling": "continue",
                    "retry_on_failure": True
                }
            }
        }

    async def _initialize_workflow_stages(self) -> bool:
        """
        åˆå§‹åŒ–å·¥ä½œæµé˜¶æ®µ

        Returns:
            bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
        """
        try:
            stage_configs = self.workflow_config.get('pipeline_setup', {}).get('stages', [])

            default_stages = [
                WorkflowStage("input_validation", "è¾“å…¥æ•°æ®éªŒè¯", True, 5),
                WorkflowStage("cross_cli_detection", "è·¨CLIè°ƒç”¨æ£€æµ‹", True, 10),
                WorkflowStage("target_execution", "ç›®æ ‡CLIæ‰§è¡Œ", False, 25),
                WorkflowStage("result_processing", "ç»“æœå¤„ç†", True, 8),
                WorkflowStage("output_formatting", "è¾“å‡ºæ ¼å¼åŒ–", True, 3)
            ]

            # å¦‚æœé…ç½®ä¸­æœ‰é˜¶æ®µå®šä¹‰ï¼Œä½¿ç”¨é…ç½®ä¸­çš„å®šä¹‰
            if stage_configs:
                self.pipeline_stages = []
                for stage_config in stage_configs:
                    stage = WorkflowStage(
                        stage_config['name'],
                        stage_config.get('description', ''),
                        stage_config.get('required', True),
                        stage_config.get('timeout', 30)
                    )
                    self.pipeline_stages.append(stage)
            else:
                self.pipeline_stages = default_stages

            logger.info(f"å·¥ä½œæµé˜¶æ®µåˆå§‹åŒ–å®Œæˆï¼Œå…±{len(self.pipeline_stages)}ä¸ªé˜¶æ®µ")
            return True

        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å·¥ä½œæµé˜¶æ®µå¤±è´¥: {e}")
            return False

    async def _register_workflow_hooks(self) -> bool:
        """
        æ³¨å†Œå·¥ä½œæµHooks

        Returns:
            bool: æ³¨å†Œæ˜¯å¦æˆåŠŸ
        """
        try:
            self.workflow_hooks = {
                'on_workflow_start': self.on_workflow_start,
                'on_stage_complete': self.on_stage_complete,
                'on_workflow_success': self.on_workflow_success,
                'on_workflow_error': self.on_workflow_error,
                'on_pipeline_ready': self.on_pipeline_ready
            }

            logger.info("å·¥ä½œæµHooksæ³¨å†ŒæˆåŠŸ")
            return True

        except Exception as e:
            logger.error(f"æ³¨å†Œå·¥ä½œæµHookså¤±è´¥: {e}")
            return False

    async def _initialize_task_queue(self) -> bool:
        """
        åˆå§‹åŒ–ä»»åŠ¡é˜Ÿåˆ—

        Returns:
            bool: åˆå§‹åŒ–æ˜¯å¦æˆåŠŸ
        """
        try:
            self.task_queue = asyncio.Queue()
            logger.info("ä»»åŠ¡é˜Ÿåˆ—åˆå§‹åŒ–æˆåŠŸ")
            return True

        except Exception as e:
            logger.error(f"åˆå§‹åŒ–ä»»åŠ¡é˜Ÿåˆ—å¤±è´¥: {e}")
            return False

    async def _ensure_config_directory(self) -> None:
        """ç¡®ä¿é…ç½®ç›®å½•å­˜åœ¨"""
        config_dir = Path.home() / ".config" / "iflow" / "adapters"
        config_dir.mkdir(parents=True, exist_ok=True)

    def is_available(self) -> bool:
        """
        æ£€æŸ¥é€‚é…å™¨æ˜¯å¦å¯ç”¨

        Returns:
            bool: æ˜¯å¦å¯ç”¨
        """
        return (
            len(self.pipeline_stages) > 0 and
            len(self.workflow_hooks) > 0 and
            self.task_queue is not None
        )

    async def execute_task(self, task: str, context: Dict[str, Any]) -> str:
        """
        æ‰§è¡Œå·¥ä½œæµä»»åŠ¡

        Args:
            task: è¦æ‰§è¡Œçš„ä»»åŠ¡
            context: æ‰§è¡Œä¸Šä¸‹æ–‡

        Returns:
            str: æ‰§è¡Œç»“æœ
        """
        try:
            logger.info(f"æ‰§è¡ŒiFlowå·¥ä½œæµä»»åŠ¡: {task}")

            # åˆ›å»ºå·¥ä½œæµä¸Šä¸‹æ–‡
            workflow_context = WorkflowContext(
                workflow_id=context.get('workflow_id', f'workflow-{datetime.now().timestamp()}'),
                stage="execution",
                data={"task": task, **context}
            )

            # æ‰§è¡Œå·¥ä½œæµ
            result = await self._execute_workflow(workflow_context)

            return result

        except Exception as e:
            logger.error(f"æ‰§è¡Œå·¥ä½œæµä»»åŠ¡å¤±è´¥: {e}")
            return f"å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}"

    # ==================== Workflow Hookå¤„ç†å™¨ ====================

    async def on_workflow_start(self, context: WorkflowContext) -> Optional[str]:
        """
        å·¥ä½œæµå¼€å§‹Hook

        Args:
            context: å·¥ä½œæµä¸Šä¸‹æ–‡

        Returns:
            Optional[str]: å¤„ç†ç»“æœ
        """
        try:
            self.workflow_count += 1
            self.stages_processed += 1

            # è®°å½•å·¥ä½œæµå¼€å§‹
            workflow_record = {
                'type': 'workflow_start',
                'workflow_id': context.workflow_id,
                'stage': context.stage,
                'data': context.data,
                'metadata': context.metadata,
                'timestamp': datetime.now().isoformat()
            }
            self.processed_workflows.append(workflow_record)

            logger.info(f"å·¥ä½œæµå¼€å§‹: {context.workflow_id}")

            # æ£€æµ‹è·¨CLIè°ƒç”¨æ„å›¾
            user_input = context.data.get('prompt', context.data.get('task', ''))
            if not user_input:
                return None

            intent = self.parser.parse_intent(user_input, "iflow")

            if intent.is_cross_cli and intent.target_cli != self.cli_name:
                # æ‰§è¡Œè·¨CLIè°ƒç”¨
                result = await self._execute_cross_cli_workflow(
                    intent.target_cli,
                    intent.task,
                    context
                )

                if result:
                    self.cross_cli_calls_count += 1
                    return result

            return None  # ç»§ç»­æ­£å¸¸å·¥ä½œæµ

        except Exception as e:
            logger.error(f"å·¥ä½œæµå¼€å§‹Hookå¤„ç†å¤±è´¥: {e}")
            self.record_error()
            return None

    async def on_stage_complete(self, context: WorkflowContext, stage_result: Any) -> Optional[str]:
        """
        é˜¶æ®µå®ŒæˆHook

        Args:
            context: å·¥ä½œæµä¸Šä¸‹æ–‡
            stage_result: é˜¶æ®µç»“æœ

        Returns:
            Optional[str]: å¤„ç†ç»“æœ
        """
        try:
            self.stages_processed += 1

            # è®°å½•é˜¶æ®µå®Œæˆ
            stage_record = {
                'type': 'stage_complete',
                'workflow_id': context.workflow_id,
                'stage': context.stage,
                'result': str(stage_result) if stage_result else None,
                'timestamp': datetime.now().isoformat()
            }
            self.processed_workflows.append(stage_record)

            logger.debug(f"å·¥ä½œæµé˜¶æ®µå®Œæˆ: {context.workflow_id} - {context.stage}")
            return None

        except Exception as e:
            logger.error(f"é˜¶æ®µå®ŒæˆHookå¤„ç†å¤±è´¥: {e}")
            self.record_error()
            return None

    async def on_workflow_success(self, context: WorkflowContext, final_result: Any) -> Optional[str]:
        """
        å·¥ä½œæµæˆåŠŸHook

        Args:
            context: å·¥ä½œæµä¸Šä¸‹æ–‡
            final_result: æœ€ç»ˆç»“æœ

        Returns:
            Optional[str]: å¤„ç†ç»“æœ
        """
        try:
            # è®°å½•å·¥ä½œæµæˆåŠŸ
            success_record = {
                'type': 'workflow_success',
                'workflow_id': context.workflow_id,
                'result': str(final_result) if final_result else None,
                'duration': (datetime.now() - context.start_time).total_seconds(),
                'timestamp': datetime.now().isoformat()
            }
            self.processed_workflows.append(success_record)

            logger.info(f"å·¥ä½œæµæˆåŠŸå®Œæˆ: {context.workflow_id}")
            return None

        except Exception as e:
            logger.error(f"å·¥ä½œæµæˆåŠŸHookå¤„ç†å¤±è´¥: {e}")
            self.record_error()
            return None

    async def on_workflow_error(self, context: WorkflowContext, error: Exception) -> Optional[str]:
        """
        å·¥ä½œæµé”™è¯¯Hook

        Args:
            context: å·¥ä½œæµä¸Šä¸‹æ–‡
            error: é”™è¯¯ä¿¡æ¯

        Returns:
            Optional[str]: å¤„ç†ç»“æœ
        """
        try:
            # è®°å½•å·¥ä½œæµé”™è¯¯
            error_record = {
                'type': 'workflow_error',
                'workflow_id': context.workflow_id,
                'error': str(error),
                'error_type': type(error).__name__,
                'timestamp': datetime.now().isoformat()
            }
            self.processed_workflows.append(error_record)

            logger.error(f"å·¥ä½œæµæ‰§è¡Œé”™è¯¯: {context.workflow_id} - {error}")
            return None

        except Exception as e:
            logger.error(f"å·¥ä½œæµé”™è¯¯Hookå¤„ç†å¤±è´¥: {e}")
            self.record_error()
            return None

    async def on_pipeline_ready(self, pipeline_config: Dict) -> Optional[str]:
        """
        æµæ°´çº¿å°±ç»ªHook

        Args:
            pipeline_config: æµæ°´çº¿é…ç½®

        Returns:
            Optional[str]: å¤„ç†ç»“æœ
        """
        try:
            logger.info("iFlowæµæ°´çº¿å·²å°±ç»ª")
            return None

        except Exception as e:
            logger.error(f"æµæ°´çº¿å°±ç»ªHookå¤„ç†å¤±è´¥: {e}")
            self.record_error()
            return None

    # ==================== è·¨CLIåŠŸèƒ½ ====================

    async def _execute_cross_cli_workflow(
        self,
        target_cli: str,
        task: str,
        context: WorkflowContext
    ) -> Optional[str]:
        """
        æ‰§è¡Œè·¨CLIå·¥ä½œæµ

        Args:
            target_cli: ç›®æ ‡CLIå·¥å…·
            task: è¦æ‰§è¡Œçš„ä»»åŠ¡
            context: å·¥ä½œæµä¸Šä¸‹æ–‡

        Returns:
            Optional[str]: æ‰§è¡Œç»“æœ
        """
        try:
            logger.info(f"æ‰§è¡Œè·¨CLIå·¥ä½œæµ: {target_cli} -> {task}")

            # è®°å½•è·¨CLIè°ƒç”¨
            workflow_execution = {
                'workflow_id': context.workflow_id,
                'target_cli': target_cli,
                'task': task,
                'stage': context.stage,
                'timestamp': datetime.now().isoformat()
            }
            self.workflow_executions.append(workflow_execution)

            # è·å–ç›®æ ‡CLIé€‚é…å™¨
            target_adapter = self.get_adapter(target_cli)

            if not target_adapter:
                logger.warning(f"ç›®æ ‡CLIé€‚é…å™¨ä¸å¯ç”¨: {target_cli}")
                return self._format_workflow_error(
                    target_cli,
                    task,
                    f"ç›®æ ‡CLIå·¥å…· '{target_cli}' ä¸å¯ç”¨æˆ–æœªå®‰è£…"
                )

            if not target_adapter.is_available():
                logger.warning(f"ç›®æ ‡CLIå·¥å…·ä¸å¯ç”¨: {target_cli}")
                return self._format_workflow_error(
                    target_cli,
                    task,
                    f"ç›®æ ‡CLIå·¥å…· '{target_cli}' å½“å‰ä¸å¯ç”¨"
                )

            # æ„å»ºæ‰§è¡Œä¸Šä¸‹æ–‡
            execution_context = {
                'source_cli': self.cli_name,
                'target_cli': target_cli,
                'original_task': task,
                'workflow_context': context.__dict__,
                'timestamp': datetime.now().isoformat()
            }

            # æ‰§è¡Œä»»åŠ¡
            result = await target_adapter.execute_task(task, execution_context)

            # è®°å½•æˆåŠŸçš„è·¨CLIè°ƒç”¨
            self.processed_requests.append({
                'type': 'cross_cli_workflow_execution',
                'target_cli': target_cli,
                'task': task,
                'workflow_id': context.workflow_id,
                'success': True,
                'result_length': len(result),
                'timestamp': datetime.now().isoformat()
            })

            # æ ¼å¼åŒ–ç»“æœ
            formatted_result = self._format_workflow_result(target_cli, result, context)

            logger.info(f"è·¨CLIå·¥ä½œæµæ‰§è¡ŒæˆåŠŸ: {target_cli}")
            return formatted_result

        except Exception as e:
            logger.error(f"è·¨CLIå·¥ä½œæµæ‰§è¡Œå¤±è´¥: {target_cli}, {e}")

            # è®°å½•å¤±è´¥çš„è·¨CLIè°ƒç”¨
            self.processed_requests.append({
                'type': 'cross_cli_workflow_execution',
                'target_cli': target_cli,
                'task': task,
                'workflow_id': context.workflow_id,
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            })

            return self._format_workflow_error(target_cli, task, str(e))

    async def _execute_workflow(self, context: WorkflowContext) -> str:
        """
        æ‰§è¡Œå·¥ä½œæµ

        Args:
            context: å·¥ä½œæµä¸Šä¸‹æ–‡

        Returns:
            str: æ‰§è¡Œç»“æœ
        """
        try:
            # è§¦å‘å·¥ä½œæµå¼€å§‹Hook
            start_result = await self.on_workflow_start(context)
            if start_result:
                return start_result

            # æ‰§è¡Œå„ä¸ªé˜¶æ®µ
            final_result = None
            for stage in self.pipeline_stages:
                stage_context = WorkflowContext(
                    workflow_id=context.workflow_id,
                    stage=stage.name,
                    data=context.data
                )

                # æ‰§è¡Œé˜¶æ®µ
                stage_result = await self._execute_stage(stage, stage_context)

                # è§¦å‘é˜¶æ®µå®ŒæˆHook
                await self.on_stage_complete(stage_context, stage_result)

                if stage_result is not None:
                    final_result = stage_result

            # è§¦å‘å·¥ä½œæµæˆåŠŸHook
            await self.on_workflow_success(context, final_result)

            return final_result or "å·¥ä½œæµæ‰§è¡Œå®Œæˆ"

        except Exception as e:
            # è§¦å‘å·¥ä½œæµé”™è¯¯Hook
            await self.on_workflow_error(context, e)
            raise

    async def _execute_stage(self, stage: WorkflowStage, context: WorkflowContext) -> Any:
        """
        æ‰§è¡Œå·¥ä½œæµé˜¶æ®µ

        Args:
            stage: å·¥ä½œæµé˜¶æ®µ
            context: å·¥ä½œæµä¸Šä¸‹æ–‡

        Returns:
            Any: é˜¶æ®µç»“æœ
        """
        try:
            stage.start_time = datetime.now()
            stage.status = "running"

            # è¿™é‡Œå¯ä»¥æ ¹æ®é˜¶æ®µåç§°æ‰§è¡Œä¸åŒçš„é€»è¾‘
            if stage.name == "cross_cli_detection":
                return await self._stage_cross_cli_detection(context)
            elif stage.name == "target_execution":
                return await self._stage_target_execution(context)
            elif stage.name == "result_processing":
                return await self._stage_result_processing(context)
            elif stage.name == "output_formatting":
                return await self._stage_output_formatting(context)
            else:
                # é»˜è®¤å¤„ç†
                return f"é˜¶æ®µ {stage.name} æ‰§è¡Œå®Œæˆ"

        except Exception as e:
            stage.status = "failed"
            stage.error = str(e)
            raise
        finally:
            stage.end_time = datetime.now()
            if stage.error is None:
                stage.status = "completed"

    async def _stage_cross_cli_detection(self, context: WorkflowContext) -> Any:
        """è·¨CLIæ£€æµ‹é˜¶æ®µ"""
        user_input = context.data.get('prompt', context.data.get('task', ''))
        intent = self.parser.parse_intent(user_input, "iflow")
        return intent

    async def _stage_target_execution(self, context: WorkflowContext) -> Any:
        """ç›®æ ‡æ‰§è¡Œé˜¶æ®µ"""
        # è¿™ä¸ªé˜¶æ®µçš„é€»è¾‘åœ¨on_workflow_startä¸­å·²ç»å¤„ç†
        return None

    async def _stage_result_processing(self, context: WorkflowContext) -> Any:
        """ç»“æœå¤„ç†é˜¶æ®µ"""
        return "ç»“æœå¤„ç†å®Œæˆ"

    async def _stage_output_formatting(self, context: WorkflowContext) -> Any:
        """è¾“å‡ºæ ¼å¼åŒ–é˜¶æ®µ"""
        return "è¾“å‡ºæ ¼å¼åŒ–å®Œæˆ"

    def _format_workflow_result(
        self,
        target_cli: str,
        result: str,
        context: WorkflowContext
    ) -> str:
        """
        æ ¼å¼åŒ–å·¥ä½œæµç»“æœ

        Args:
            target_cli: ç›®æ ‡CLIå·¥å…·
            result: æ‰§è¡Œç»“æœ
            context: å·¥ä½œæµä¸Šä¸‹æ–‡

        Returns:
            str: æ ¼å¼åŒ–çš„ç»“æœ
        """
        return f"""## ğŸ”„ è·¨CLIå·¥ä½œæµç»“æœ

**æºå·¥ä½œæµ**: iFlow Pipeline ({context.workflow_id})
**ç›®æ ‡CLI**: {target_cli.upper()}
**å·¥ä½œæµé˜¶æ®µ**: {context.stage}
**æ‰§è¡Œæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

---

{result}

---

*æ­¤ç»“æœç”±iFlowè·¨CLIé›†æˆç³»ç»Ÿé€šè¿‡Workflow Pipelineæä¾›*"""

    def _format_workflow_error(
        self,
        target_cli: str,
        task: str,
        error_message: str
    ) -> str:
        """
        æ ¼å¼åŒ–å·¥ä½œæµé”™è¯¯ç»“æœ

        Args:
            target_cli: ç›®æ ‡CLIå·¥å…·
            task: åŸå§‹ä»»åŠ¡
            error_message: é”™è¯¯ä¿¡æ¯

        Returns:
            str: æ ¼å¼åŒ–çš„é”™è¯¯ç»“æœ
        """
        return f"""## âŒ è·¨CLIå·¥ä½œæµå¤±è´¥

**æºå·¥ä½œæµ**: iFlow Pipeline
**ç›®æ ‡CLI**: {target_cli.upper()}
**é”™è¯¯ä¿¡æ¯**: {error_message}
**å¤±è´¥æ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

è¯·æ£€æŸ¥ç›®æ ‡CLIå·¥å…·æ˜¯å¦æ­£ç¡®å®‰è£…å’Œé…ç½®ã€‚

---

*æ­¤é”™è¯¯ç”±iFlowè·¨CLIé›†æˆç³»ç»ŸæŠ¥å‘Š*"""

    # ==================== æµ‹è¯•å…¼å®¹æ–¹æ³• ====================

    def _detect_cross_cli_intent(self, context: WorkflowContext) -> bool:
        """
        æ£€æµ‹è·¨CLIè°ƒç”¨æ„å›¾ï¼ˆæµ‹è¯•å…¼å®¹æ–¹æ³•ï¼‰

        Args:
            context: å·¥ä½œæµä¸Šä¸‹æ–‡

        Returns:
            bool: æ˜¯å¦ä¸ºè·¨CLIè°ƒç”¨
        """
        try:
            user_input = context.data.get('prompt', context.data.get('task', ''))
            if not user_input:
                return False

            intent = self.parser.parse_intent(user_input, "iflow")
            return intent.is_cross_cli

        except Exception:
            return False

    def _parse_cross_cli_task(self, context: WorkflowContext) -> tuple:
        """
        è§£æè·¨CLIä»»åŠ¡ï¼ˆæµ‹è¯•å…¼å®¹æ–¹æ³•ï¼‰

        Args:
            context: å·¥ä½œæµä¸Šä¸‹æ–‡

        Returns:
            tuple: (target_cli, task)
        """
        try:
            user_input = context.data.get('prompt', context.data.get('task', ''))
            if not user_input:
                return None, None

            intent = self.parser.parse_intent(user_input, "iflow")
            if intent.is_cross_cli:
                return intent.target_cli, intent.task

            return None, None

        except Exception:
            return None, None

    async def _execute_cross_cli_workflow_call(
        self,
        target_cli: str,
        task: str,
        context: WorkflowContext
    ) -> str:
        """
        æ‰§è¡Œè·¨CLIå·¥ä½œæµè°ƒç”¨ï¼ˆæµ‹è¯•å…¼å®¹æ–¹æ³•ï¼‰

        Args:
            target_cli: ç›®æ ‡CLIå·¥å…·
            task: è¦æ‰§è¡Œçš„ä»»åŠ¡
            context: å·¥ä½œæµä¸Šä¸‹æ–‡

        Returns:
            str: æ‰§è¡Œç»“æœ
        """
        result = await self._execute_cross_cli_workflow(target_cli, task, context)
        if result:
            return result
        return f"è·¨CLIå·¥ä½œæµè°ƒç”¨å¤±è´¥: {target_cli} -> {task}"